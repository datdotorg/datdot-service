const varint = require('varint')
const WebSocket = require('ws')

const { performance } = require('perf_hooks')

const datdot_crypto = require('datdot-crypto')
const logkeeper = require('datdot-logkeeper')
const storage_report_codec = require('datdot-codec/storage-report')
const proof_codec = require('datdot-codec/proof')

const makeSets = require('_makeSets')
const PriorityQueue = require('_priority-queue')

const DB = require('./DB')
const blockgenerator = require('./scheduleAction.js')
const b4a = require('b4a')


const priority_queue = PriorityQueue(compare)
function compare (item) { return item }
const blockinterval = 5000 // in miliseconds
var header = { number: 0 }
const scheduler = init()
const connections = {}
var eventpool = []
var mempool = []


const setSize = 10 // every contract is for hosting 1 set = 10 chunks
const size = setSize*64 //assuming each chunk is 64kb
const blockTime = 6000
const maxPauseTimeAllowed = 360 // 1h

/******************************************************************************
   INIT
******************************************************************************/

async function init () {
  const [json, logport] = process.argv.slice(2)
  const config = JSON.parse(json)
  const [host, PORT] = config.chain
  const name = `chain`
  const log = await logkeeper(name, logport)
  const wss = new WebSocket.Server({ port: PORT }, after)
  function after () {
    log({ type: 'chain', data: `running on http://localhost:${wss.address().port}` })
  }
  const scheduler = blockgenerator({ blockinterval, intrinsics }, log.sub('blockgenerator'), async blockMessage => {
    const { number, startTime } = blockMessage.data
    const currentBlock = header.number = number
    const temp = [...mempool]
    mempool = []
    try {
      while (temp.length) {
        if ((performance.now() - startTime) < (blockinterval - 200)) {
          const extrinsic = temp.shift() // later take out the ones which offers highest gas
          await extrinsic()
        } else {
          const text = `not able to execute the remaining ${temp.length} extrinsics in mempool during blockinterval`
          log({ type: 'warn', data: text })
          mempool = [...temp, ...mempool]
          emitBlock()
          return
        }
      }
      emitBlock()
    } catch (error) {
      const stack = error.stack
      log({ type: 'Error', data: { text: 'failed-mempool', stack } })
    }
    async function emitBlock () {
      log({ type: 'eventpool', data: { text: `event pool in emitBlock`, data: eventpool } })
      const temp_pool = [...eventpool]
      eventpool = []
      temp_pool.forEach(([log, message]) => {
        log({ type: 'chain', data: { text: `emit chain event`, data: JSON.stringify(message) } })
      })
      const promises = Object.entries(connections).map(([name, { ws, handler }]) => new Promise((resolve, reject) => {
        ws.send(JSON.stringify(blockMessage))
        temp_pool.forEach(([log, message]) => { handler(message) })
        resolve()
      }))
      await Promise.all(promises)
      log({ type: 'current-block', data: currentBlock })
    }
  })
  wss.on('connection', function connection (ws, req) {
    const ip = req.socket.remoteAddress
    const port = req.socket.remotePort
    log({ type: 'connection-from', data: { ip, port } })
    ws.on('message', async function incoming (message) {
      var { flow, type, data } = JSON.parse(message)
      const [from, id] = flow
      // log({ type: 'extrinsic', data: { type, flow, messsage: JSON.parse(message) } })

      const method = queries[type]
      if (method) {
        const result = await method(data, from, data => {
          // log({ type: 'chain', data: { text: `send data after ${type} to: ${from}` } })
          ws.send(JSON.stringify({ cite: [flow], type: 'data', data }))
        })
        if (result === undefined) return log({ type: 'error', data: { text: 'Query not found', type, flow, message: JSON.parse(message) } })
        const msg = { cite: [flow], type: 'done', data: result }
        // log({ type: 'chain', data: { text: `sending ${type} to: ${from}` } })
        return void ws.send(JSON.stringify(msg))
      }

      if (!connections[from] && DB.lookups.userByAddress[data.address]) {
        const userlog = log.sub(from)
        connections[from] = { name: from, counter: 0, ws, log: userlog, handler: data => ws.send(JSON.stringify({ data })) }
      }

      if (id === 0 && type === 'newUser') {
        mempool.push(() => makeNewUser(data, from, flow, ws))// a new connection
      } else {
        mempool.push(() => {
          signAndSend(type, flow, data, from, data => {
            // _log({ type: 'chain', data: [`send data after "${type}" to: ${from}`] })
            ws.send(JSON.stringify({ cite: [flow], type: 'data', data }))
          })
      })
      }
    })
    ws.on('open', function open () {
      log('======= OPEN =======')
    })
    ws.on('error', function error (err) {
      log('======= OPEN =======')
      log(err)
    })
    ws.on('close', function close () {
      log('[ERROR] unexpected closing of chain connection for', name)
    })
  })
  /*----------------------
    ROUTING (sign & send)
  ------------------------*/
  async function signAndSend (msgtype, flow, data, name, status) {
    const { log, ws } = connections[name]
    log({ type: 'execute-extrinsic', data: msgtype })

    try {
      if (msgtype === 'submitStorageChallenge') {
        data = storage_report_codec.decode(data, log)
      }
      const { type, args, nonce, address } = data
      
      status({ events: [], status: { isInBlock:1 } })
      
      const user = await _getUser(address, { name, nonce }, status)
      if (!user) return void log({ type: 'chain', data: [`UNKNOWN SENDER of: ${data}`] }) // TODO: maybe use status() ??
      else if (type === 'registerForWork') _register_for_work(user, { name, nonce }, status, args)
      else if (type === 'publishPlan') _publish_plan(user, { name, nonce }, status, args)
      else if (type === 'unpublishPlan') _unpublishPlan(user, { name, nonce }, status, args)
      else if (type === 'hostingSetupReport') _hostingSetup_report(user, { name, nonce }, status, args)
      else if (type === 'hosterReplacementReport') _hosterReplacement_report(user, { name, nonce }, status, args)
      else if (type === 'submitStorageChallenge') _storage_challenge_report(user, { name, nonce }, status, args)
      else if (type === 'submitPerformanceChallenge') _performance_challenge_report(user, { name, nonce }, status, args)
      else if (type === 'pause') _pause({ user, args })
      else if (type === 'unpause') _unpause(user, { name, nonce }, status, args)
      // else if ...
      else ws.send(JSON.stringify({ cite: [flow], type: 'error', data: 'unknown type' }))
    } catch (error) {
      log({ type: 'chain', data: { text: 'error: chain.js' } })
      log({ type: 'Error', data: { type: msgtype, error } })
    }
  }
  /*----------------------
        MAKE NEW USER
  ------------------------*/
  async function makeNewUser (data, from, flow, ws) {
    const { args, nonce, address } = data
    // 1. do we have that user in the database already?
    // @TODO: We shouldn't know the user's name (=from)
    if  (from && address && !connections[from] && !DB.lookups.userByAddress[address]) {
      const userlog = log.sub(from)
      connections[from] = { name: from, counter: 0, ws, log: userlog, handler: data => ws.send(JSON.stringify({ data })) }
      // TODO:
      if (!messageVerifiable(data)) return 
      // add user and address and user data to database
      _newUser(args, from, address, userlog)
    }
    else {
      log({ type: 'chain', data: { text: 'error: name is already taken', from } })
      return ws.send(JSON.stringify({
        cite: [flow], type: 'error', data: 'name is already taken'
      }))
    }
  }
  return scheduler
}

/******************************************************************************
  API
******************************************************************************/

/*----------------------
      QUERIES
------------------------*/
const queries = {
  getItemByID,
  getFeedByID,
  getFeedByKey,
  getUserByID,
  getUserIDByNoiseKey,
  getUserIDBySigningKey,
  getPlanByID,
  getAmendmentByID,
  getContractByID,
  getStorageChallengeByID,
  getPerformanceChallengeByID,
}
function getItemByID (id) { return getItem(id) }
function getDatasetByID (id) { return getItem(id) }
function getFeedByID (id) { return getItem(id) }
function getUserByID (id) { return getItem(id) }
function getPlanByID (id) { return getItem(id) }
function getContractByID (id) { return getItem(id) }
function getAmendmentByID (id) { return getItem(id) }
function getStorageChallengeByID (id) { return getItem(id) }
function getPerformanceChallengeByID (id) { return getItem(id) }

function getFeedByKey (key) {
  const keyBuf = b4a.from(key, 'hex')
  return DB.lookups.feedByKey[keyBuf.toString('hex')]
}
function getUserIDByNoiseKey(key) {
  const keyBuf = b4a.from(key, 'hex')
  const id = DB.lookups.userIDByNoiseKey[keyBuf.toString('hex')]
  return id
}
function getUserIDBySigningKey(key) {
  const keyBuf = b4a.from(key, 'hex')
  return DB.lookups.userIDBySigningKey[keyBuf.toString('hex')]
}

async function _getUser (address, { name, nonce }, status) {
  const log = connections[name].log
  const pos = DB.lookups.userByAddress[address]
  const user = getUserByID(pos)
  log({ type: 'chain', data: `Existing user: ${name}, ${user.id}, ${address}` })
  return user
}

/*----------------------
      STORE ITEM
------------------------*/
function addItem (item) {
  if ('id' in item) throw new Error('new items cannot have "id" property')
  const id = DB.storage.length
  item.id = id
  DB.storage.push([item])
  return id
}
function getItem (id) {
  if (!Number.isInteger(id)) return
  if (id < 0) return
  const len = DB.storage.length
  if (id >= len) return
  const history = DB.storage[id]
  if (!Array.isArray(history)) return
  const next = history.length
  const item = history[next - 1]
  return item
}
function delItem (id) {
  if (!Number.isInteger(id)) return
  if (id < 0) return
  const len = DB.storage.length
  if (id >= len) return
  const history = DB.storage[id]
  if (!Array.isArray(history)) return
  return !!history.push(void 0)
}
function updateItem (id, item) {
  if (!Number.isInteger(id)) return
  if (id < 0) return
  const len = DB.storage.length
  if (id >= len) return
  const history = DB.storage[id]
  if (!Array.isArray(history)) return
  return !!history.push(item)
}

/*----------------------
      NEW USER
------------------------*/
async function _newUser (args, name, address, log) {
  let [data] = args
  const { signingPublicKey, noiseKey } = data
  const signingKeyBuf = b4a.from(signingPublicKey, 'hex')
  const noiseBuf = b4a.from(noiseKey, 'hex')

  const user = { 
    address, 
    noiseKey,
    signingKey: signingPublicKey, 
    form: {},
    idleStorage: 0,
    reputation: 0,
    balance: 0,
    status: {}
  }
  addItem(user)
  DB.lookups.userByAddress[address] = user.id
  DB.lookups.userIDBySigningKey[signingKeyBuf.toString('hex')] = user.id
  DB.lookups.userIDByNoiseKey[noiseBuf.toString('hex')] = user.id
  log({ type: 'chain', data: [`New user: ${name}, ${JSON.stringify(user)}`] })
}

/*----------------------
      REGISTER FOR WORK
------------------------*/
async function _register_for_work (user, { name, nonce }, status, args) {
  const log = connections[name].log
  let [form] = args
  const { components } = form
  const { resources_ids, performances_ids, timetables_ids, regions_ids } = await publish_form_components(components)

  form.timetables = form.timetables.map(ref => { if (ref < 0) return timetables_ids[(Math.abs(ref) - 1)] })
  form.regions = form.regions.map(ref => { if (ref < 0) return regions_ids[(Math.abs(ref) - 1)] })
  form.performances = form.performances.map(ref => { if (ref < 0) return performances_ids[(Math.abs(ref) - 1)] })
  form.resources = form.resources.map(ref => { if (ref < 0) return resources_ids[(Math.abs(ref) - 1)] })
  user.form = form
  user.idleStorage = getItem(form.resources[0]).storage
  log({ type: 'register', data: [`Registering for work`] })
  ;['encoder', 'hoster', 'attester'].forEach(role => registerRole (user, role, log))
}

/*----------------------
  (UN)REGISTER ROLES
------------------------*/
async function registerRole (user, role, log) {
  const userID = user.id
  // registered.push(role)
  if (!user[role]) {
    user[role] = {
      tasks: {},
      challenge: {},
      capacity: 2, // TODO: calculate capacity for each task based on the resources from the form
    }
  }
  const first = role[0].toUpperCase()
  const rest = role.substring(1)
  DB.status[`idle${first + rest}s`].push(userID)
  next_task(log)
}

/*----------------------
      PUBLISH FEED
------------------------*/
// TODO:
// * we wont start hosting a plan before the check
// * 3 attesters
// * provide signature for highest index in ranges
// * provide all root hash sizes required for ranges
// => native api feed.getRoothashes() provides the values

/*----------------------
      (UN)PUBLISH PLAN
------------------------*/
async function _publish_plan (user, { name, nonce }, status, args) {
  const log = connections[name].log
  log({ type: 'chain', data: [`Publishing a plan`] })
  let [data] = args
  const { plan, components, proofs = {}  } = data
  const { program } = plan
  const feed_ids = await Promise.all(components.feeds.map(async feed => await publish_feed(feed, user.id, log)))
  const verified = await verify_and_store(proofs, feed_ids, log)
  if (!verified) return log({ type: 'chain', data: [`Error:  Proofs could not be verified`] })
  const component_ids = await publish_plan_components(log, components, feed_ids)

  const updated_program = []
  for (var i = 0, len = program.length; i < len; i++) {
    const item = program[i]
    if (item.plans) updated_program.push(...getPrograms(item.plan))
    else updated_program.push(handleNew(item, component_ids))
  }
  plan.program = updated_program
  if (!planValid({ plan })) return log({ type: 'chain', data: [`Error:  Plan from and/or until are invalid`] })
  plan.sponsor = user.id

  plan.contracts = []
  const id = addItem(plan)

  priority_queue.add({ type: 'plan', id })
  next_plan(priority_queue.take(), log) // schedule the plan execution
}

async function _unpublishPlan (user, { name, nonce }, status, args) {
  const log = connections[name].log
  const [planID] = args
  log({ type: 'chain', data: { text: `unpublishPlan`, args, planID }})
  const plan = getPlanByID(planID)
  if (!plan.sponsor === user.id) return log({ type: 'chain', data: [`Error:  Only a sponsor is allowed to unpublish the plan`] })
  cancelContracts(plan, log) // remove all hosted and draft contracts
}

/*----------------------
  AMENDMENT REPORT
------------------------*/
async function _hostingSetup_report (user, { name, nonce }, status, args) {
  const log = connections[name].log
  const meta = [user, name, nonce, status]
  const [ report ] = args
  const { id: amendmentID, failed, signatures } = report // [2,6,8]
  log({ type: 'chain', data: { text: 'Amendment report', report: JSON.stringify(report) } })
  const amendment = getAmendmentByID(amendmentID)
  const { contract: contractID, sid } = amendment
  const { hosters, attesters, encoders } = amendment.providers
  const contract = getContractByID(contractID)
  const feedObj = getFeedByID(contract.feed)
  const [attesterID] = attesters
  // check if right attester
  if (user.id !== attesterID) return log({ type: 'chain', data: { text: `Error: this user can not submit the attestation`, providers: JSON.stringify(amendment.providers), user: user.id } })
  // new amendment was already done so this one is not important anymore
  if (contract.amendments[contract.amendments.length - 1] !== amendmentID) return log({ type: 'chain', data: { text: `Error: this amendment has expired`, amendmentID } })
  // cancel amendment schedule
  const { cancelAction } = await scheduler
  if (!sid) log({ type: 'chain', data: { text: 'No scheduler for', contract } })
  cancelAction(sid)

if (failed.length) {
  amendment.status = 'fail'
  const failedIDs = failed.map(key => getUserIDByNoiseKey(b4a.from(key, 'hex')))
  // unbooking and pausing is done in retry_amendment
  _retry_amendment({ failed: failedIDs, amendmentID, log })
  return 
}
  // verify hosters' signatures
  const verified = verify_hosters_sigs({ hosters, failed, signatures, amendmentID, log })
  if (!verified) return log({ type: 'chain', data: { text: `Error: unique_el_signature for hoster: ${hoster_id} could not be verified` } })
  log({ type: 'chain', data: { text: `amendmentReport hoster signatures verified`, amendmentID } })
  
  amendment.status = 'done'
  feedObj.contracts.push(contractID)
  encoders.forEach(id => unbook_and_rate({ id, role: 'encoder', task: amendmentID,  type: 'setup', status: 'done', log }))
  attesters.forEach(id => unbook_and_rate({ id, role: 'attester', task: amendmentID,  type: 'setup', status: 'done', log }))
  
  trigger_challenges({ hosters, contractID, amendmentID, feedObj, log})

  // => until HOSTING STARTED event, everyone keeps the data around
  emitEvent('hostingStarted', [amendmentID], log)
  return
}

/*----------------------------------
      HOSTER REPLACEMENT REPORT
------------------------------------*/

async function _hosterReplacement_report (user, { name, nonce }, status, args) {
  const log = connections[name].log
  const meta = [user, name, nonce, status]
  const [ report ] = args
  const { id: amendmentID, failed } = report 
  const amendment = getAmendmentByID(amendmentID)
  const { contract: contractID, sid, positions } = amendment
  const { hosters, attesters, encoders } = amendment.providers
  const contract = getContractByID(contractID)
  const feedObj = getFeedByID(contract.feed)
  const [attesterID] = attesters
  const task = amendmentID
  const type = 'hosterReplacement' 
  log({ type: 'chain', data: { text: 'Hoster replacement report', report: JSON.stringify(report), providers: JSON.stringify(amendment.providers)  } })
  
  // check if right attester
  if (user.id !== attesterID) return log({ type: 'chain', data: { text: `Error: this user can not submit the attestation`, providers: JSON.stringify(amendment.providers), user: user.id } })
  
  if (!contract.amendments.includes(amendmentID)) return log({ type: 'chain', data: [`Error: not a valid hoster replacement report`, amendmentID] })
 
  if (
    amendment.status === 'done'
    || amendment.status === 'fail'
    || amendment.status === 'timed-out'
  ) return log({ type: 'chain', data: { text: `Error: this amendment has expired`, amendmentID, status: amendment.status } })
  // check if right amendment
  // while hosterReplacement is in progress and we call start replacement for a new hoster, 
  // it's ok, because previous replacement will fail (as one of the active hosters
  // is obviously not 'active' anymore otherwise new replacement wouldn't happen) 
  // => this results with Warning: this amendment for hosterReplacement has expired

    // cancel amendment schedule
    const { cancelAction } = await scheduler
    if (!sid) log({ type: 'chain', data: { text: 'No scheduler for', contract } })
    cancelAction(sid)

  if (contract.amendments[contract.amendments.length - 1] !== amendmentID) {
    log({ type: 'chain', data: [`Warning: this amendment is not relevant anymore, there is a new amendment in progress`, amendmentID] })
    for (const id of hosters) {
      unbook_and_rate({ id, role: 'hoster', task, type, status: 'unknown', log })
    }
    for (const pos of positions) { // unbook all replacement encoders
      const id = encoders[pos]
      unbook_and_rate({ id, role: 'encoder', task, type, status: 'unknown', log })
    }
    for (const id of attesters) unbook_and_rate({ id, role: 'attester', task, type, status: 'done', log }) 
    return
  }

  if (failed.length) {
    amendment.status = 'fail'
    const failedIDs = failed.map(key => getUserIDByNoiseKey(b4a.from(key, 'hex')))
    for (const id of hosters) { // unbook all hosters (replacement and active)
      if (failedIDs.includes(id)) {
        // unbook & pause the failed ones
        const user = getUserByID(id)
        _pause({ args: { status: 'fail', log }, user })
        unbook_and_rate({ id, role: 'hoster', task, type, status: 'fail', log })
      } 
      else unbook_and_rate({ id, role: 'hoster', task, type, status: 'unknown', log })
    }
    for (const pos of positions) { // unbook all replacement encoders
      const id = encoders[pos]
      if (failedIDs.includes(id)) {
        // unbook and pause all failed
        const user = getUserByID(id)
        _pause({ args: { status: 'fail', log }, user })
        unbook_and_rate({ id, role: 'encoder', task, type, status: 'fail', log })
      } else unbook_and_rate({ id, role: 'encoder', task, type, status: 'unknown', log })
    }
    for (const id of attesters) unbook_and_rate({ id, role: 'attester', task, type, status: 'done', log }) 
    // retry
    _retry_hosterReplacement({ failed: failedIDs, amendmentID, log })
  } else {
    amendment.status = 'done'
    // unbook
    for (var i = 0; i < hosters.length; i++) {
      if (positions.includes(i)) continue
      unbook_and_rate({ id: hosters[i], role: 'hoster', task, type, status: 'done', log })
    }
    for (const id of attesters) unbook_and_rate({ id, role: 'attester', task, type, status: 'done', log }) 
    for (const pos of positions) {
      unbook_and_rate({ id: encoders[pos], role: 'encoder', task, type, status: 'done', log })
      // start challenges for new hoster
      trigger_challenges({ hosters: [hosters[pos]], contractID, amendmentID, feedObj, log })
    }
  }
}

/*----------------------
  STORAGE CHALLENGE
------------------------*/

async function _storage_challenge_report (user, { name, nonce }, status, args) {
  const log = connections[name].log
  log({ type: 'storage challenge', data: { text: `Received storage challenge response`, args: JSON.stringify(args) } })
  const [ response ] = args
  const user_id = user.id
  const { storageChallengeID: challenge_id,  status: res_status, proof_of_contact, reports } = response
  const storageChallenge = getStorageChallengeByID(challenge_id)
  const { attester: attester_id, hoster: hoster_id, checks } = storageChallenge
  const contract_ids = Object.keys(checks).map(stringID => Number(stringID))
  try {
    for (const contract_id of contract_ids) {
      const { feed: feed_id } = getContractByID(contract_id)
      const { feedkey } = await getFeedByID(feed_id)
      checks[contract_id].feedkey = feedkey
    }
    const challenged_hoster = getUserByID(hoster_id)
    const hosterSigningKeyBuf = b4a.from(challenged_hoster.signingKey, 'hex')
    const { challenge } = challenged_hoster.hoster 

    
    const unique_el = `${challenge_id}`
    const unique_el_buff = b4a.from(unique_el, 'binary')
    
    var att_status
    var host_status
    const type = 'storage'
    
    const valid_report = is_valid_report({ attester_id, user_id, challenge, challenge_id })
    if (!valid_report) return log({ type: 'storage challenge', data: { text: `error: This not a valid challenge`, challenge_id, challenge: challenge.cid, attester_id, user_id, hoster: challenged_hoster.id } })

    if (res_status === 'fail') {
      storageChallenge.status = 'fail'
      challenged_hoster.hoster.challenge.status = storageChallenge.status
      log({ type: 'storage challenge', data: { text: `: error - hoster timed out`, hoster_id, proof_of_contact } })
      att_status = 'unknown'
      host_status = 'fail'
      _pause({ args: { status: 'fail', log }, user: challenged_hoster })
      unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
      unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { all, proved }, log })
      
      const active_amendments = getActiveAmendmentsFor(challenged_hoster)
      const amendmentIDs = active_amendments.map(amendment => amendment.id)
      for (const amendmentID of amendmentIDs) {
        log({ type: 'storage challenge', data: { text: `calling drop hosting and start hoster replacement for failed hoster`, active_amendments, tasks: Object.keys(challenged_hoster.hoster.tasks), amendmentID, task: challenged_hoster.hoster.tasks[amendmentID] } })
        await dropHosting({ amendmentID, userID: challenged_hoster.id, type: 'hosting', status: 'cancel', log })
        await start_HosterReplacement({ failedHosters: [challenged_hoster.id], amendmentID, log })
      }
      return await cleanup_and_new_storage_challenge({ user: challenged_hoster, log })
    }
    if (!proof_of_contact || !reports || !res_status) {
      storageChallenge.status = 'fail'
      challenged_hoster.hoster.challenge.status = storageChallenge.status
      log({ type: 'storage challenge', data: { text: `: error: in storage challenge`, proof_of_contact, reports, res_status } })
      att_status = 'fail'
      _pause({ args: { status: 'fail', log }, user: getUserByID(attester_id) })
      host_status = 'unknown'
      unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
      unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { all, proved }, log })
      return await cleanup_and_new_storage_challenge({ user: challenged_hoster, log })
    }
    // verify proof of contact error
    if (res_status === 'invalid-proof' || res_status === 'no-data') {
      storageChallenge.status = 'fail'
      challenged_hoster.hoster.challenge.status = storageChallenge.status
      host_status = 'fail'
      _pause({ args: { status: 'fail', log }, user: challenged_hoster })
      att_status = 'unknown' // if 'done' then attester can just report invalid-signature and get paid
      log({ type: 'storage challenge', data: { text: `: error: hoster failed the challenge: invalid signature`, proof_of_contact } })
      unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
      unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { all, proved }, log })

      const active_amendments = getActiveAmendmentsFor(challenged_hoster)
      const amendmentIDs = active_amendments.map(amendment => amendment.id)
      for (const amendmentID of amendmentIDs) {
        log({ type: 'storage challenge', data: { text: `calling drop hosting and start hoster replacement for failed hoster`, active_amendments, tasks: Object.keys(challenged_hoster.hoster.tasks), amendmentID, task: challenged_hoster.hoster.tasks[amendmentID] } })
        await dropHosting({ amendmentID, userID: challenged_hoster.id, type: 'hosting', status: 'cancel', log })
        await start_HosterReplacement({ failedHosters: [challenged_hoster.id], amendmentID, log })
      }
      
      return await cleanup_and_new_storage_challenge({ user, log })
    } else if (res_status === 'success') {
      const proof_buff = b4a.from(proof_of_contact, 'hex')
      const valid_proof = datdot_crypto.verify_signature(proof_buff, unique_el_buff, hosterSigningKeyBuf)
      if (!valid_proof) { // attester failed to report invalid-signature
        att_status = 'fail'
        _pause({ args: { status: 'fail', log }, user: getUserByID(attester_id) })
        host_status = 'unknown'
        log({ type: 'storage challenge', data: { text: `: error: attester provided invalid hoster signature`, valid_proof } })
        unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
        unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { all, proved }, log })  
        return await cleanup_and_new_storage_challenge({ user: challenged_hoster, log })
      }
    }
    
    if (reports.length !== Object.keys(checks).length) {
      storageChallenge.status = 'fail'
      challenged_hoster.hoster.challenge.status = storageChallenge.status
      att_status = 'fail'
      _pause({ args: { status: 'fail', log }, user: getUserByID(attester_id) })
      host_status = 'unknown'
      log({ type: 'storage challenge', data: { text: `: error: storage challenge report`, reports_len: reports.length, checks_len: Object.keys(checks).length } })
    } else {
      // attester succeeded, evaluate report & start a new challenge
      storageChallenge.status = 'done'
      challenged_hoster.hoster.challenge.status = storageChallenge.status
      att_status = 'done'
      var { status, all, proved } = await analyse_reports({ checks, reports, log })
      challenged_hoster.hoster.challenge.status = status
      host_status = status
      log({ type: 'storage challenge', data: { text: `Storage challenge analysis`, challenge_id, status, all, proved } })
    }
    unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
    unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { all, proved }, log })
    await cleanup_and_new_storage_challenge({ user: challenged_hoster, log })
  } catch(err) {
    log({ type: 'storage challenge', data: { text: `error: storage challenge`, challenge_id, attester_id, err } })
  }

}

async function analyse_reports ({ checks, reports, log }) {
  log({ type: 'storage challenge', data: { text: `Analysing reports`, reports, checks } })
  // verify proofs for each contract hoster was challenged
  var proved = 0 
  for (var i = 0, len = reports.length; i < len; i++) {
    if (reports[i] === 'failed') continue
    let { contractID, p } = reports[i]
    let { index, feedkey } = checks[`${contractID}`] 
    if (p.block.index !== index) log({ type: 'storage challenge', data: { text: 'error: index in check and proof do not match' } })
    feedkey = b4a.from(feedkey, 'hex')
    const proof_verified = await datdot_crypto.verify_proof(p, feedkey)
    proof_verified ? proved++ : log({ type: 'storage challenge', data: { text: 'error: proof not verified' } })
  }
  return { status: 'done', all: reports.length, proved }
}

async function cleanup_and_new_storage_challenge ({ user, log }) {
  var { cid, sid } = user.hoster.challenge
  const { scheduleAction, cancelAction } = await scheduler
  const status = user.hoster.challenge.status
  if (status === 'stop') return
  if (status === 'done' || status === 'fail') {
    cancelAction(sid) // scheduled action id
    log({ type: 'chain', data: {text:'RESET old storage challenge', items: { hosterID: user.id, status, cid, sid } }})
  }
  
  // currently we replace the hoster as soon as they fail (in hoster replacement report)
  // TODO: should match hosterReplacement
  if (status === 'fail') return 
  // another challenge already in progress
  if (status === 'active' || status === 'pending') return 

  log({ type: 'chain', data: { text: 'Start new storage challenge', finished_challenge: { hosterID: user.id, status, cid, sid } } })
  scheduleAction({ from: log, data: {hoster_id: user.id}, delay: 5, type: 'make_storage_challenge' })
}
/*----------------------
  PERFORMANCE CHALLENGE
------------------------*/

async function _performance_challenge_report (user, { name, nonce }, status, args) {
  const log = connections[name].log
  const [ challenge_id, reports ] = args
  const hoster_ids = Object.keys(reports).map(string_id => Number(string_id))
  const user_id = user.id
  log({ type: 'performance challenge', data: { text: `Submitting report`, challenge_id, user_id, hoster_ids, reports_len: Object.keys(reports).length } })
  const { attesters, feed: feedID } = getPerformanceChallengeByID(challenge_id)
  const [attester_id] = attesters
  const feedObj = getFeedByID(feedID)
  const { challenge, contracts: contractIDs } = feedObj
  
  var att_status
  var host_status
  const type = 'performance'
  
  const valid_report = is_valid_report({ attester_id, user_id, challenge, challenge_id })
  if (!valid_report) return log({ type: 'performance challenge', data: { text: `error: This not a valid challenge`, attester_id, user_id, challenge, challenge_id } })
  
  if (!reports || !hoster_ids.length) { 
    feedObj.challenge.status = 'fail'
    att_status = 'fail'
    _pause({ args: { status: 'fail', log }, user: getUserByID(attester_id) })
    host_status = 'unknown'
    log({ type: 'performance challenge', data: { text: `Error: This challenge's report is empty`, challenge_id } })
    unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
    // unbook also all hosters
    for (const contract_id of contractIDs) {
      const contract = getContractByID(contract_id)
      const { amendments } = contract
      const active_amendment = getAmendmentByID(amendments[amendments.length-1])
      var { hosters } = active_amendment.providers
      for (const hoster_id of hosters) {
        unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, log })
      }
    }
    await cleanup_and_new_performance_challenge(feedID, log)
    return
  }
  
  log({ type: 'performance challenge', data: { text: `looping over hoster ids`, hoster_ids } })
  
  for (const hoster_id of hoster_ids) {
    const { stats, proof_of_contact } = reports[hoster_id]
    if (reports[hoster_id].status === 'fail') {
      feedObj.challenge.status = 'fail'
      att_status = 'done'
      host_status = 'fail'
      _pause({ args: { status: 'fail', log }, user: getUserByID(hoster_id) })
      unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { grade: 1 }, log })
      log({ type: 'performance challenge', data: { text: `error: hoster failed the challenge ${challenge_id}, ${hoster_id}` } })
    } else {
      const grade = grade_performance(stats, hoster_id, log)
      const proof_buff = b4a.from(proof_of_contact, 'hex')
      const data = b4a.from(challenge_id.toString(), 'binary')
      const hosterkey = b4a.from(getUserByID(hoster_id).signingKey, 'hex')
      const proof_verified = datdot_crypto.verify_signature(proof_buff, data, hosterkey)
      log({ type: 'performance challenge', data: { text: `proof valid`, challenge_id } })
      if (!stats || !proof_of_contact || !proof_verified) {
        feedObj.challenge.status = 'fail'
        att_status = 'fail'
        _pause({ args: { status: att_status, log }, user: getUserByID(attester_id) })
        host_status = 'unknown'
        unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, type, status: host_status, opts: { grade }, log })
        log({ type: 'performance challenge', data: { text: `error: attester failed`, challenge_id } })
      } else {
        att_status = 'done'
        host_status = 'done'
        log({ type: 'performance challenge', data: { text: `Hoster successfully completed performance challenge`, hoster_id, feedID, challenge_id } })
        unbook_and_rate({ id: hoster_id, role: 'hoster', task: challenge_id, status: host_status, type, opts: { grade }, log })
      }
    }
  }
  
  if (feedObj.challenge.status !== 'fail') {
    log({ type: 'performance challenge', data: { text: `Performance challenge successfully completed`, challenge_id, old_status: feedObj.challenge.status } })
    feedObj.challenge.status = 'done'
  }
  unbook_and_rate({ id: attester_id, role: 'attester', task: challenge_id, type, status: att_status, log })
  await cleanup_and_new_performance_challenge(feedID, log)
}

async function cleanup_and_new_performance_challenge (feedID, log) {
  const feedObj = getFeedByID(feedID)
  const { challenge } = feedObj
  const { status, cid, sid } = challenge
  log({ type: 'chain', data: { text: 'Start new performance challenge', items: { feedID, status, cid, sid } } })
  const { scheduleAction, cancelAction } = await scheduler
  if (status === 'done' || status === 'timed-out' || status === 'fail') { cancelAction(sid) } // cancel scheduled action id
  scheduleAction({ from: log, data: {feedID}, delay: 5, type: 'make_performance_challenge' })
}

function grade_performance (stats, hoster_id, log) {
  var grade
  if (!stats) grade = 1
  else {
    if (0 <= stats.latency <= 100) grade = 1
    else if (101 <= stats.latency <= 200) grade = 0.95
    else if (201 <= stats.latency <= 300) grade = 9
    else if (301 <= stats.latency <= 400) grade = 0.85
    else if (401 <= stats.latency <= 500) grade = 0.8
    else if (501 <= stats.latency <= 600) grade = 0.75
    else if (601 <= stats.latency <= 700) grade = .7
    else if (701 <= stats.latency <= 800) grade = .65
    else if (801 <= stats.latency <= 900) grade = 0.6
    else if (901 <= stats.latency <= 1000) grade = 0.55
    else if (1001 <= stats.latency <= 1100) grade = 0.5
    else if (1101 <= stats.latency <= 1200) grade = 0.45
    else if (1201 <= stats.latency <= 1300) grade = 0.4
    else if (1201 <= stats.latency <= 1300) grade = 0.35
    else if (1301 <= stats.latency <= 1400) grade = 0.3
    else if (1401 <= stats.latency <= 1500) grade = 0.2
    else if (stats.latency > 1500) grade = 0
  }
  log({ type: 'performance challenge', data: { text: `logging stats to grade the performance`, stats, hoster_id, grade } })
  return grade
}

/******************************************************************************
  SCHEDULABLE INTRINSICS
******************************************************************************/
const intrinsics = { 
  plan_execution, 
  amendment_timeout, 
  make_storage_challenge, 
  make_performance_challenge, 
  storage_challenge_timeout,
  performance_challenge_timeout,
  hoster_replacement_timeout
 }

async function plan_execution (log, data) {
  const { contract_id: contractID } = data
  const providers = { encoders: [], attesters: [], hosters: [] }
  const type = 'hostingSetup'
  const amendment_id = await init_amendment({ contractID, providers, type, log })
  log({ type: 'chain', data: { text: 'Plan execution', contractID, amendment_id } })
  DB.queues.tasks.push({ fnName: type, id: amendment_id }) // TODO: sort tasks based on priority (RATIO!)
  next_task(log)
}

async function storage_challenge_timeout (log, data) {
  const { user } = data // user is a hoster
  var { timestamp, cid } = user.hoster.challenge
  user.hoster.challenge.status = 'timed-out'
  const storageChallenge = getStorageChallengeByID(cid)
  storageChallenge.status = 'timed-out'
  const { hoster: hoster_id, attester: attester_id} = storageChallenge
  log({ type: 'storage-challenge', data: { text: `error: storage challenge timeout ${cid}, hoster: ${user.id}, attester: ${attester_id}` } })
  if (hoster_id !== user.id) return log({ type: 'storage-challenge', data: { text: 'error: not the right hoster', hoster_id, user_id: user.id } })
  _pause({ args: { status: 'fail', log }, user: getUserByID(attester_id) })
  _pause({ args: { status: 'fail', log }, user: getUserByID(hoster_id) })
  unbook_and_rate({ id: attester_id, role: 'attester', task: cid, type: 'storage', status: 'fail', log })
  unbook_and_rate({ id: hoster_id, role: 'hoster', task: cid, type: 'storage', status: 'unknown', log })
  await cleanup_and_new_storage_challenge({ user, log })
}

async function performance_challenge_timeout (log, data) {
  const { feedID } = data
  const feed = getFeedByID(feedID)
  const { status, timestamp, cid } = feed.challenge
  feed.challenge.status = 'timed-out'
  log({ type: 'performance-challenge-timeout', data: { text: 'error: performance challenge timeout', status, cid, perf: performance.now() - timestamp} })
  const performanceChallenge = getPerformanceChallengeByID(cid)
  const attesterIDs = performanceChallenge.attesters
  attesterIDs.forEach(id => unbook_and_rate({ id, role: 'attester', task: cid,  type: 'performance', status: 'fail', log }))
  await cleanup_and_new_performance_challenge(feedID, log)
}

async function amendment_timeout (log, data) {
  const { id } = data
  log({ type: 'chain', data: { text: 'Amendment timed out', id } })
  const amendment = getAmendmentByID(id)
  const { providers: { attesters, hosters, encoders }, status } = amendment
  // const failed = [...attesters]
  const failed = [...attesters, ...hosters, ...encoders]
  // TODO: handle (details in retry_amendment, do we need status too?)
  if (status === 'init') {
    amendment.status = 'timed-out'
    _retry_amendment({ failed, amendmentID: id, log}) // we pause & unbook failed in retry_amendment
  }
}

async function hoster_replacement_timeout (log, data) {
  const { id: amendmentID } = data
  log({ type: 'chain', data: { text: 'Error: Hoster replacement timed out', amendmentID } })
  const amendment = getAmendmentByID(amendmentID)
  amendment.status = 'timed-out'

  const { positions, providers: { encoders, attesters, hosters } } = amendment
  for (const id of attesters) {
    const user = getUserByID(id)
    _pause({ args: { status: 'fail', log }, user })
    unbook_and_rate({ id, role: 'attester', task: amendmentID, type: 'hosterReplacement', status: 'fail', log })
  }
  for (const id of hosters) {
    unbook_and_rate({ id, role: 'hoster', task: amendmentID, type: 'hosterReplacement', status: 'unknown', log })
  }
  for (const pos of positions) {
    const id = encoders[pos]
    unbook_and_rate({ id, role: 'encoder', task: amendmentID, type: 'hosterReplacement', status: 'unknown', log })
  }
  // we certainly know attester failed, but can't know for others
  const failed = [...attesters]
  await _retry_hosterReplacement({ failed, amendmentID, log })
}

async function make_storage_challenge (log, data) {
  // select an attester
  // tell them which hoster to challenge
  // tell them which subset of contracts & chunks to challenge
  const { hoster_id } = data
  const user = getUserByID(hoster_id)
  const status = user.hoster.challenge.status
  if (status === 'pending' || status === 'active') return
  log({ type: 'storage', data: { text: 'Scheduler executed: Make new storage challenge', hoster_id } })
  const amendments = getActiveAmendmentsFor(user)
  const contract_ids = amendments.map(amendment => amendment.contract)
  const active_contracts = []
  for (const id of contract_ids) {
    const contract = getContractByID(id)
    if (contract.status !== 'cancelled') active_contracts.push({ id, ranges: contract.ranges })
  }
  log({ type: 'storage', data: { text: 'New storage challenge amendments and contracts', user_hoster_tasks: JSON.stringify(user.hoster.tasks), amendments, contract_ids, contractsToCheck } })
  if (!active_contracts.length) return

  var contractsToCheck = active_contracts.length > 20 ? 
    get_random_ids({ items: active_contracts, max: 20 }) : active_contracts
  log({ type: 'storage', data: { text: 'New storage challenge for contracts', contract_ids, contractsToCheck } })
  const checks = {}
  for (const obj of contractsToCheck ) {
    const { ranges, id: contractID } = obj
    checks[contractID] = { index: getRandomChunk(ranges) }
  }
  const storage_challenge = { checks, hoster: hoster_id }
  const id = addItem(storage_challenge)
  const timestamp = performance.now()
  user.hoster.challenge = { status: 'pending', timestamp, cid: id }
  log({ type: 'chain', data: { text: 'Making new storage challenge for', items: { task_id: id, hoster_id, user: JSON.stringify(user), amendments, cid: id } } })
  // push to tasks
  DB.queues.tasks.push({ fnName: 'storageChallenge', id })
  next_task(log)
}

async function make_performance_challenge (log, data) {
  const { feedID } = data
  const feed = getFeedByID(feedID)
  if (!feed.contracts.length) {
    log({ type: 'chain', data: { text: 'Error: no feed contracts for', feedID } })
    scheduleAction({ from: log, data: {feedID}, delay: 5, type: 'make_performance_challenge' })
    return
  }
  const performanceChallenge = { feed: feedID }
  const id = addItem(performanceChallenge)
  const type = 'performanceChallenge'
  DB.queues.tasks.push({ fnName: type, id })
  next_task(log)
}

/******************************************************************************
  HELPERS
******************************************************************************/

function messageVerifiable (message) {
  // 1. verify MICRO PROOF OF WORK
  // 2. is the message verifiable, pubkeys, noisekeys, signatures?
  return true
}

async function publish_feed (feed, sponsor_id, log) {
  var { feedkey, swarmkey } = feed // stringkeys
  if (!b4a.isBuffer(feedkey)) feedkey = b4a.from(feedkey, 'hex')
  if (!b4a.isBuffer(swarmkey)) swarmkey = b4a.from(swarmkey, 'hex')

  const stringkey = feedkey.toString('hex')
  const stringswarmkey = swarmkey.toString('hex')

  // check if feed already exists
  if (DB.lookups.feedByKey[stringkey]) return
  feed = { feedkey: stringkey, swarmkey: stringswarmkey, signatures: {}, contracts: [], challenge: {} }
  const feedID = addItem(feed)
  DB.lookups.feedByKey[stringkey] = feedID
  feed.publisher = sponsor_id
  log({ type: 'chain', data: { text: 'publishing feed', feedID, feedkey  }})
  emitEvent('FeedPublished', [feedID], log)
  return feedID
}

async function verify_and_store (proofs, feed_ids, log) {
  const all = proofs.map(async ({ feed_ref, p }, i) => {
    // parse proof and turn signature & node hashes into buffers
    const feed_id = feed_ref < 0 ? feed_ids[(Math.abs(feed_ref) - 1)] : feed_ref
    const feed = getFeedByID(feed_id)
    const feedkey = b4a.from(feed.feedkey, 'hex')

    p = proof_codec.to_buffer(p)
    const verified = await datdot_crypto.verify_proof(p, feedkey)
    if (!verified) return false
    log({ type: 'info', data: { text: 'Success: Signature verified' } })
    const len = verified.upgrade.length
    feed.signatures[len] = verified.upgrade.signature
  })
  await Promise.all(all)
  return true
}

async function publish_plan_components (log, components, feed_ids) {
  const { dataset_items, performance_items, timetable_items, region_items } = components
  const dataset_ids = await Promise.all(dataset_items.map(async item => {
    if (item.feed_id < 0) item.feed_id = feed_ids[(Math.abs(item.feed_id) - 1)]
    return addItem(item)
  }))
  const performances_ids = await Promise.all(performance_items.map(async item => addItem(item)))
  const timetables_ids = await Promise.all(timetable_items.map(async item => addItem(item)))
  const regions_ids = await Promise.all(region_items.map(async item => addItem(item)))
  return { dataset_ids, performances_ids, timetables_ids, regions_ids }
} 
async function publish_form_components (components) {
  const {  timetable_items, region_items, performance_items, resource_items } = components
  const timetables_ids = await Promise.all(timetable_items.map(async item => addItem(item)))
  const regions_ids = await Promise.all(region_items.map(async item => addItem(item)))
  const performances_ids = await Promise.all(performance_items.map(async item => addItem(item)))
  const resources_ids = await Promise.all(resource_items.map(async item => addItem(item)))
  return { resources_ids, performances_ids, timetables_ids, regions_ids }
}
function handleNew (item, ids) {
  const keys = Object.keys(item)
  for (var i = 0, len = keys.length; i < len; i++) {
    const type = keys[i]
    item[type] = item[type].map(id => {
      if (id < 0) return ids[`${type}_ids`][(Math.abs(id) - 1)]
    })
  }
  return item
}

function getPrograms (plans) {
  const programs = []
  for (var i = 0; i < plans.length; i++) { programs.push(...plans[i].programs) }
  return programs
}

async function next_plan (next, log) {
  const plan = await getPlanByID(next.id)
  const contract_ids = await make_contracts(plan, log)
  plan.contracts.push(...contract_ids)
  for (var i = 0, len = contract_ids.length; i < len; i++) {
    const contract_id = contract_ids[i]
    const blockNow = header.number
    const delay = plan.duration.from - blockNow
    const { scheduleAction } = await scheduler
    scheduleAction({ 
      from: log,
      type: 'plan_execution',
      data: { contract_id }, 
      delay,
    })
  }
}

// split plan into sets with 10 chunks
async function make_contracts (plan, log) {
  const dataset_ids = plan.program.map(item => item.dataset).flat()
  const datasets = get_datasets(plan)
  for (var i = 0; i < datasets.length; i++) {
    const feed = getFeedByID(datasets[i].feed_id)
    const ranges = datasets[i].ranges
    // split ranges to sets (size = setSize)
    log({ type: 'chain', data: { text: `make sets`, ranges, setSize, plan: JSON.stringify(plan) } })
    const sets = makeSets({ ranges, setSize })
    return Promise.all(sets.map(async set => {
      // const contractID = DB.contracts.length
      const contract = {
        plan: plan.id,
        feed: feed.id,
        ranges: set,
        amendments: [],
        status: 'pending'
       }
      const id = addItem(contract)
      const c = getItemByID(id)
      log({ type: 'chain', data: [`New Contract: ${JSON.stringify(contract)}`] })
      return contract.id 
    }))
  }
}
// find providers for each contract (+ new providers if selected ones fail)
async function init_amendment (opts) {
  const { contractID, providers, type, positions, ref, log } = opts
  const contract = getContractByID(contractID)
  if (!contract) return log({ type: 'chain', data: `Error: No contract with this ID: ${contractID}` })
  log({ type: 'chain', data: { text: `Init amendment & find additional providers for contract: ${contractID}`, type }})
  // const id = DB.amendments.length
  const amendment = { contract: contractID }
  // DB.amendments.push(amendment) // @NOTE: set id
  const id = addItem(amendment)
  amendment.providers = providers
  amendment.type = type
  amendment.status = 'init'
  contract.amendments.push(id)
  if (type === 'hosterReplacement') {
    amendment.positions = positions
    amendment.ref = ref
  }
  log({ text: 'initializing amendment', amendment: JSON.stringify(amendment), contract: JSON.stringify(contract) })
  return id
}

function getProviders (plan, reuse, task_id, log) {
  if (!reuse) reuse = { encoders: [], attesters: [], hosters: [] }
  const attesterAmount = 1 - (reuse.attesters.length || 0)
  const encoderAmount = 3 - (reuse.encoders.length || 0)
  const hosterAmount = 3 - (reuse.hosters.length || 0)
  const avoid = {}
  avoid[plan.sponsor] = true
  reuse.encoders.forEach(id => avoid[id] = true)
  reuse.attesters.forEach(id => avoid[id] = true)
  reuse.hosters.forEach(id => avoid[id] = true)

  const reused_attesters = reuse.attesters.map((id, index) => ({  id, index, role: 'attester' }))
  const reused_hosters = reuse.hosters.map((id, index) => ({  id, index, role: 'attester' }))
  const reused_encoders = reuse.encoders.map((id, index) => ({  id, index, role: 'encoder' }))

  log({ type: 'chain', data: { text: `getProviders`, reuse, attesterAmount, encoderAmount,hosterAmount} })

  // TODO: backtracking!! try all the options before returning no providers available
  const attesters = attesterAmount >= 1 ? 
    select({ idleProviders: DB.status.idleAttesters, role: 'attester', amount: attesterAmount, avoid, plan, log }) : []
  if (attesters.length !== attesterAmount) {
    log({ type: 'chain', data: { text:`error: missing attesters`} })
    return 
  }
  const encoders = encoderAmount >= 1 ? 
    select({ idleProviders: DB.status.idleEncoders, role: 'encoder', amount: encoderAmount, avoid, plan, log }) : []
  if (encoders.length !== encoderAmount) {
    log({ type: 'chain', data: { text:`error: missing encoders`} })
    return 
  }
  const hosters = hosterAmount >= 1 ? 
    select({ idleProviders: DB.status.idleHosters, role: 'hoster', amount: hosterAmount, avoid, plan, log }) : []
  if (hosters.length !== hosterAmount) {
    log({ type: 'chain', data: { text:`error: missing hosters`} })
    return 
  }

  return {
    attesters: [...attesters, ...reused_attesters],
    hosters: [...hosters, ...reused_hosters],
    encoders: [...encoders, ...reused_encoders]
  }
}
function getRandomIndex(range) {
  const min = range[0]
  const max = range[1]+1
  return Math.floor(Math.random() * (max - min)) + min; //The maximum is exclusive and the minimum is inclusive
}
function getRandomChunk (ranges) { // [[0,3], [5,7]]
  const start = 0
  const end = ranges.length
  const range = ranges[Math.floor(Math.random() * (end - start)) + start]
  return getRandomIndex(range)
}
function select ({ idleProviders, role, amount, avoid, plan, log }) {
  if (amount < 1) return
  idleProviders.sort(() => Math.random() - 0.5) // TODO: improve randomness
  const selectedProviders = []
  for (var i = 0; i < idleProviders.length; i++) {
    const id = idleProviders[i]
    if (avoid[id]) continue // if id is in avoid, don't select it
    const provider = getUserByID(id)
    if (doesQualify(plan, provider, role, log)) {
      selectedProviders.push({id, index: i, role })
      avoid[id] = true
      if (selectedProviders.length === amount) return selectedProviders
    }
  }
  return []
}
function book ({ type, selectedProviders, role, task_id, log }) {
  log({ type: 'chain', data: { text: `Book task`, type, selectedProviders, role, task_id } })
  for (var i = 0, len = selectedProviders.length; i < len; i++) {
    const provider = getUserByID(selectedProviders[i].id)
    provider[role].tasks[task_id] = type
    log({ type: 'chain', data: { text: `Task booked`, type, selectedProviders, role, task_id, tasks: provider[role].tasks  } })
    if (role === 'hoster' && type === 'storage') continue
    if (role === 'hoster' && type === 'performance') continue
    provider.idleStorage -= size
  }
}

function verify_hosters_sigs ({ hosters, failed, signatures, amendmentID, log }) {
  try {
    for (var i = 0, len = hosters.length; i < len; i++) {
      const hoster_id = hosters[i]
      if (failed.includes(hoster_id)) continue
      const sig = signatures[hoster_id]
      if (!sig) {
        failed.push(hoster_id)
        continue
      }
      // log({ type: 'chain', data: { text: 'Getting signature', hoster_id, signatures, one_sig: sig } })
      const sig_buf = Buffer.isBuffer(sig) ? sig : b4a.from(sig, 'hex')
      const data = b4a.from(amendmentID.toString(), 'binary')
      const signingKey  = b4a.from(getUserByID(hoster_id).signingKey)
      log({ type: 'chain', data: { text: 'Verifying signatures', sig: sig_buf, data, signingKey: signingKey.toString('hex') } })
      return datdot_crypto.verify_signature(sig_buf, data, signingKey)
    }
  } catch(err) {
    log({ type: 'chain', data: { text: `error in verify_hosters`, err } })
  }
}

function is_valid_report ({ attester_id, user_id, challenge, challenge_id }) {
  const { cid, status } = challenge
  if (attester_id !== user_id || cid !== challenge_id || status !== 'active' ) return false
  else return true
}

// TODO: payments: for each successfull hosting we pay attester(1/3), this hoster (full), encoders (full, but just once)

function unbook_and_rate ({ id, role, task, status, type, opts, log }) {
  const user = getUserByID(id) 
  log({ type: 'chain', data: { text: `Unbooking and rating`,  type, task, role, status } })
  if (!user[role].tasks[task]) return log({ type: 'chain', data: { text: `Error: Not a valid task ${task}, ${role}, ${type}, ${JSON.stringify(user)}` } })
  var reward
  var grade
  
  if (role === 'hoster') {
    if (type === 'hostingSetup' && status === 'fail') { // fail
      grade = 1
      delete user[role].tasks[task]
      if (!DB.status.idleHosters.includes(id) && !user.status.paused) {
        DB.status.idleHosters.push(id)
      }
    }
    else if (type === 'hosterReplacement') {
      reward = 20
      if (status === 'done') grade = 1
      else if (status === 'fail') grade = 1
      delete user[role].tasks[task]
    }
    else if (type === 'storage') { // storage challenge
      var all
      if (!opts) {
        const { checks } = getItem(task)
        all = Object.keys(checks).length
      } else {
        all = opts.all
        var proved = opts.proved
      }
      reward = 50 * proved
      const success_rate = (proved/all).toFixed(1)
      if (status === 'done') grade = success_rate * all
      else if (status === 'fail') grade = all
      delete user[role].tasks[task]
      // if (success_rate < 0.8) { find replacement & update the user.idleStorage }        
    } 
    else if (type === 'performance') { // performance challenge
      grade = opts.grade // expected vs. delivered performance
      if (status === 'done') {
        if (opts.grade === 1) reward = 50
        if (0.95 < opts.grade < 1) reward = 45
        if (0.9 < opts.grade < 0.95) reward = 40
        if (0.85 < opts.grade < 0.9) reward = 35
        if (0.8 < opts.grade < 0.85) reward = 30
        if (0.75 < opts.grade < 0.8) reward = 25
        if (0.5 < opts.grade < 0.75) reward = 20
        if (0.3 < opts.grade < 0.5) reward = 10
        if (opts.grade < 0.3) reward = 5
      }
      delete user[role].tasks[task]
    }
    else if (type === 'hosting') { 
      if (status === 'pause') { // hoster will be available when they unpause()
        user.idleStorage += size
        delete user[role].tasks[task]    
      }
      else if (status === 'cancel') { // hoster is again available for jobs
        if (!DB.status.idleHosters.includes(id)) DB.status.idleHosters.push(id)
        user.idleStorage += size
        delete user[role].tasks[task]    
      }
    }
}

else if (role === 'attester') {
  if (type === 'hostingSetup') reward = 5
  else if (type === 'storageChallenge') reward = 10
  else if (type === 'performanceChallenge') reward = 10
  else if (type === 'hosterReplacement') reward = 5
  grade = 1
  delete user[role].tasks[task]
  if (!DB.status.idleAttesters.includes(id) && !user.status.paused) {
    DB.status.idleAttesters.push(id)
  }
  user.idleStorage += size
}
else if (role === 'encoder') {
  reward = 5
  grade = 1
  delete user[role].tasks[task]
  if (!DB.status.idleEncoders.includes(id) && !user.status.paused) {
    DB.status.idleEncoders.push(id)
  }
  user.idleStorage += size
}

// UPDATE BALANCE AND REPUTATION
if (status === 'done') {
  user.balance += reward 
  user.reputation += grade 
}
if (status === 'fail') user.reputation -= grade
if (status === 'undefined' || status === 'unknown') {
  if (role === 'hoster') if (!DB.status.idleHosters.includes(id)) DB.status.idleHosters.push(id)
  else if (role === 'attester') if (!DB.status.idleAttesters.includes(id)) DB.status.idleAttesters.push(id)
  else if (role === 'encoder') if (!DB.status.idleEncoders.includes(id)) DB.status.idleEncoders.push(id)
  user.idleStorage += size
  delete user[role].tasks[task]
}
next_task(log)
}

async function _pause ({ user, args }) {
  const { status, until, log } = args
  const block = getBlockNumber()
  removeFromIdle(user.id, log)
  log({ type: 'pause', data: { texts: 'pausing user', user_id: user.id, status, paused: user.status.paused, block } })
  
  if (status === 'fail') { // we assume it's a computer or network glitch
    // 1. reduce reputation
    // user.reputation -= 20 reputation is already reduced in unbook_and_rate()
    // 2. forced pause for 10min and wait for unpause
    if (user.status.paused) return
    user.status.paused = { until: block + 60 }
    // 3. set timeout for hosters
    if (isHoster(user)) {
      replaceOtherPausedHosters({ user, log })
      setTimeout(async () => { // if no upause on time => replace
        await cancelHostingJobs({ user, log })
        // }, blockTime * 60 * 1000) // blocktime is 6s
      }, blockTime * 2 * 1000) // blocktime is 6s
    }
    emitEvent('paused', [user.id], log)
  }
  else if (status === 'pause' && until) { // pause initiated by the user (switching ISP, moving, setting up a new computer...)
    // 1. reduce reputation
  user.reputation -= 10
  const block_diff = until - block
  if (user.status.paused || block_diff > maxPauseTimeAllowed ) return
  // 2. pause for a needed timeframe
  user.status.paused = { until }
  // 3. set timeout for hosters
  if (isHoster(user)) {
    replaceOtherPausedHosters({ user, log })
    setTimeout(async () => { // if no upause on time => replace
      await cancelHostingJobs({ user, log })
    }, block_diff * blockTime * 1000) // blocktime is 6s
  }
  }
  else if (status === 'stop') { // initiated by the user for a longer period => we find replacements, because we're informed up front 
    // hoster doesn't lose reputation, but they 'lose a bit' by not getting paid from the announcement until the new hoster is set
    user.status.paused = { until: Infinity }
    if (isHoster(user)) await cancelHostingJobs({ user, log })
  }
  log({ type: 'pause', data: { texts: 'user paused', user_id: user.id, status, paused: user.status.paused, block } })
}
async function _unpause (user, { name, nonce }, args) {
  const log = connections[name].log
  log({ type: 'unpause', data: { texts: 'unpausing user', user_id: user.id } })
  
  const { until } = user.status.paused
  const block = getBlockNumber()
  if (block > until) {
   console.log({ type: 'chain', text: { text: 'error: invalid unpause - not unpaused on time' }})
  }
  if (user.status.paused) {
    user.status = {}
    addToIdle(user.id) // user is again available for jobs
    if (isHoster) {
      log({ type: 'unpause', data: { texts: 'unpausing hoster', user_id: user.id, challenge: JSON.stringify(user.hoster.challenge) } })
      // resume challenges
      const challenge_status = user.hoster.challenge.status
      if (challenge_status !== 'active' || challenge_status === 'pending') {
        log({ type: 'chain', data: { text: 'Start new storage challenge for unpaused' } })
        const { scheduleAction } = await scheduler
        scheduleAction({ from: log, data: {hoster_id: user.id}, delay: 5, type: 'make_storage_challenge' })    }
      }
  } else {
    throw Error('invalid unpause', { cause: 'no status paused' })
  }
}
function isHoster (user) {
  return user.hoster.tasks.length
}
async function cancelHostingJobs ({ user, log }) {
  const active_amendments = getActiveAmendmentsFor(user)
  const amendmentIDs = active_amendments.map(amendment => amendment.id)
  log({ type: 'chain', data: { texts: 'cancel hosting jobs', user_id: user.id, amendmentIDs } })
  for (const id of amendmentIDs) {
    await dropHosting({ amendmentID: id, userID: user.id, type: 'hosting', status: 'cancel', log })
    await start_HosterReplacement({ failedHosters: [user.id], amendmentID: id, log })
  }
}
async function start_HosterReplacement ({ failedHosters, amendmentID, avoid, log }) {
  // while hosterReplacement is in progress and we call start replacement for a new hoster, 
  // it's ok, because previous replacement will fail (as one of the active hosters)
  // is obviously not 'alive' anymore => this results with Error: this amendment for hosterReplacement has expired
  log({ type: 'chain', data: { texts: 'starting hoster replacement', failedHosters } })
  const { contract: contractID } = getAmendmentByID(amendmentID)
  const { amendments } = getContractByID(contractID)

  /* 
  scenarios:
  - no hoster replacements yet (type: 'hostingSetup', status: 'done')
  - successful hoster replacement (type: 'hosterReplacement', status: 'done')
  - hoster replacement in progress for another hoster (type: 'hosterReplacement', status: 'init)
  */
  var hosters, attesters, encoders
  var positions = []
  var ref
  for (var i = amendments.length; i--;) {
    const id = amendments[i]
    const amendment = getAmendmentByID(id)
    const { providers, status, type } = amendment
    log({ type: 'chain', data: { texts: 'looping over amendments', amendment: JSON.stringify(amendment) } })
    if (type ==='hosterReplacement' && status === 'done') {
      ref = id
      hosters = providers.hosters
      attesters = providers.attesters
      encoders = providers.encoders
      break
    } 
    else if (type ==='hosterReplacement' && status === 'init') {
      ref = amendment.ref
      positions.push(...amendment.positions)
      const ref_amendment = getAmendmentByID(ref)
      hosters = ref_amendment.providers.hosters
      attesters = ref_amendment.providers.attesters
      encoders = ref_amendment.providers.encoders
      break
    }
    else if (type ==='hosterReplacement' && (status === 'fail' || status === 'timed-out')) {
      ref = amendment.ref
      positions.push(...amendment.positions)
      const ref_amendment = getAmendmentByID(ref)
      hosters = ref_amendment.providers.hosters
      attesters = ref_amendment.providers.attesters
      encoders = ref_amendment.providers.encoders
      break
    }
    else if (type ==='hostingSetup' && status === 'done') {
      ref = id
      hosters = providers.hosters
      attesters = providers.attesters
      encoders = providers.encoders
      break
    }
    else return
  }
  log({ type: 'chain', data: { texts: 'start hoster replacement', failedHosters, avoid, positions, hosters: JSON.stringify(hosters) } })
  const len = hosters.length
  var providers = { hosters: [...hosters], encoders: [...encoders] }
  for (var i = 0; i < len; i++) {
    if (failedHosters.includes(hosters[i])) positions.push(i)
  }
  if (positions.length > 2) {
    log({ type: 'chain', data: { texts: 'error: all 3 hosters need to be replaced, hosting replacement can not be done', contractID } })
    setTimeout(async() => {
      const opts = { contractID, providers, type: 'hosterReplacement', positions, ref, log }
      const new_amendment_id = await init_amendment(opts)
      DB.queues.tasks.push({ fnName: 'hosterReplacement', avoid: avoid || {}, id: new_amendment_id })
      next_task(log)
    }, 5000)
    return
  }
  const opts = { contractID, providers, type: 'hosterReplacement', positions, ref, log }
  const new_amendment_id = await init_amendment(opts)
  DB.queues.tasks.push({ fnName: 'hosterReplacement', avoid: avoid || {}, id: new_amendment_id })
  next_task(log)
}
  
async function _retry_hosterReplacement ({ failed, amendmentID, log }) {
  log({ type: 'chain', data: { texts: 'retry hoster replacement', failed, amendmentID } })
  const { providers: { hosters }, contract: contractID } = getAmendmentByID(amendmentID)
  const contract = getContractByID(contractID)
  // new amendment was already done so this one is not important anymore
  if (contract.amendments[contract.amendments.length - 1] !== amendmentID) return log({ type: 'chain', data: { text: `Error: this amendment has been replaced`, amendmentID } })
  const avoid = {}
  for (const id of failed) avoid[id] = true
  const failedHosters = []
  for (const id of hosters) {
    if (failed.includes(id)) failedHosters.push(id)
  }
  await start_HosterReplacement({ failedHosters, amendmentID, avoid, log })
}
async function dropHosting ({ amendmentID, userID, type, status, log }) {
  emitEvent('dropHosting', [amendmentID, userID], log)
  log({ type: 'chain', data: { texts: 'Drop hosting', userID } })
  const user = getUserByID(userID)
  user.hoster.challenge.status = 'stop'
  var { sid } = user.hoster.challenge
  const { cancelAction } = await scheduler
  if (sid) cancelAction(sid)
  unbook_and_rate({ id: userID, role: 'hoster', task: amendmentID, type, status, log })
}
async function replaceOtherPausedHosters ({ user, log }) {
  // if another hoster paused for same feed range, replace the first one that got frozen
  const active_amendments = getActiveAmendmentsFor(user)
  const amendmentIDs = active_amendments.map(amendment => amendment.id)
  log({ type: 'chain', data: { texts: 'replace other paused hosters', user_id: user.id, amendmentIDs } })
  for (const id of amendmentIDs) {
    const { hosters} = getAmendmentByID(id).providers
    const other_hosters = hosters.filter(id => id !== user.id)
    other_hosters.forEach(async hoster_id => {
      const hoster = getItemByID(hoster_id)
      if (hoster.status.paused) {
        await dropHosting({ amendmentID: id, userID: user.id, type: 'hosting', status: 'cancel', log })
        start_HosterReplacement({ failedHosters: [user.id], amendmentID: id, log })
      }
    })
  }
}
function getActiveAmendmentsFor (user) {
  const amendments = Object.keys(user.hoster.tasks)
    .map(task => getItem(Number(task)))
    .filter(task => {
      // don't include tasks that are in progress or failed 
      // (i.e. hosterReplacement role for some new contract
      // that is not done yet or might even fail)
      if (task.status === 'done') return true
    })
  return amendments
}
function removeFromIdle (id, log) {
  const idleHosters = DB.status.idleHosters
  const idleAttesters = DB.status.idleAttesters
  const idleEncoders = DB.status.idleEncoders
  idleHosters.splice(idleHosters.indexOf(id), 1)
  idleAttesters.splice(idleAttesters.indexOf(id), 1)
  idleEncoders.splice(idleEncoders.indexOf(id), 1)
  log({ 
    type: 'pause', 
    data: { 
      texts: 'removed from idle', 
      id, 
      hosters: JSON.stringify(DB.status.idleHosters),  
      attesters: JSON.stringify(DB.status.idleAttesters),  
      encoders: JSON.stringify(DB.status.idleEncoders)  
    } 
  })
}
function addToIdle (id) {
  DB.status.idleHosters.push(id)
  DB.status.idleAttesters.push(id)
  DB.status.idleEncoders.push(id)
}
function doesQualify (plan, provider, role, log) {
  const schedule_compatible = isScheduleCompatible(plan, provider.form, role, log)
  const has_capacity = hasCapacity(provider, role, log)
  const enough_storage = hasEnoughStorage(provider, log)
  // log({ type: 'chain', data: { text: 'does qualify', schedule_compatible, has_capacity, enough_storage } })
  if ( schedule_compatible && has_capacity && enough_storage) return true
}
async function isScheduleCompatible (plan, form, role, log) {
  const blockNow = header.number
  const isAvialableNow = form.duration.from <= blockNow
  const until = form.duration.until
  const isOpenEnded = !until 
  var taskDuration
  if (role === 'attester') taskDuration = 3
  else if (role === 'encoder') taskDuration = 2 // duration in blocks
  else if (role === 'hoster') taskDuration = plan.duration.until -  blockNow
  return (isAvialableNow && (until >= (blockNow + taskDuration) || isOpenEnded))
}
function hasCapacity (provider, role, log) {
  const tasks = provider[role].tasks
  const used_capacity = Object.keys(tasks).length
  return (used_capacity < provider[role].capacity)
}
function hasEnoughStorage (provider, log) {
  return (provider.idleStorage > size)
}
async function next_task (log) {
  // TODO rewrite to be compatible with substrate logic
  const { scheduleAction } = await scheduler
  const temp_queue = []
  for (var start = new Date(); DB.queues.tasks.length && (new Date() - start < 4000);) {
    const next = DB.queues.tasks[0]
    // we select providers here, so the ones avail right now can be selected
    const { fnName, id: task_id, avoid = {} } = next 
    const task = getItemByID(task_id)
    log({ type: 'tasks', data: { text: 'next task', fnName, temp_queue: temp_queue.length, len: DB.status.idleAttesters.length, task: JSON.stringify(task), tasks: JSON.stringify(DB.queues.tasks) } })
    
    if (fnName === 'hostingSetup' || fnName === 'retry_hostingSetup' 
        && DB.status.idleAttesters.length 
        && DB.status.idleEncoders.length >= 3 
        && DB.status.idleHosters.length >= 3) {
      const { contract: contract_id, providers: reuse, status } = task
      if (status !== 'init') {
        DB.queues.tasks.shift()
        return
      }
      const contract = getContractByID(contract_id)
      const { plan: plan_id } = contract
      const providers = getProviders(getPlanByID(plan_id), reuse, task_id, log)
      if (providers)  {
        DB.queues.tasks.shift()
        ;['attester','encoder','hoster'].forEach(role => {
          book({ type: fnName, selectedProviders: providers[`${role}s`], role, task_id: task_id, log })
        })
        const keys = Object.keys(providers)
        for (var i = 0, len = keys.length; i < len; i++) {
          providers[keys[i]] = providers[keys[i]].map(item => item.id)
        }
        log({ type: 'chain', data: { text: `Providers for amendment (${task_id}) booked`,  providers} })
        task.providers = providers
        // set status 
        task.status = 'in progress'
        // schedule timeout action
        task.sid = scheduleAction({ from: log, data: { id: task_id }, delay: 5, type: 'amendment_timeout' })
        contract.status = 'active'
        // emit event
        emitEvent(fnName, [task_id], log)
      } else {
        DB.queues.tasks.shift()
        temp_queue.push(next)
      }
    }
    else if (fnName === 'storageChallenge' && DB.status.idleAttesters.length) {
      // TODO: schedule timeout
      const { hoster: hoster_id } = task
      const user = getUserByID(hoster_id)
      log({ type: 'storage', data: { text: 'storageChallenge in nextTask', task: JSON.stringify(task), user_paused: user.status.paused } })

      if (user.status.paused) {
        const timestamp = performance.now()
        user.hoster.challenge.status = 'cancelled'
        user.hoster.challenge.timestamp = timestamp
        DB.queues.tasks.shift()
        return // don't challenge paused hosters
      }
      avoid[hoster_id] = true
      const idleProviders = DB.status.idleAttesters
      const attesters = select({ idleProviders, role: 'attester', amount: 1, avoid, plan: {}, log })
      log({ type: 'storage', data: { text: 'next task selected providers', idle: JSON.stringify(idleProviders), avoid: JSON.stringify(avoid), selected: JSON.stringify(attesters) } })
      const [attester] = attesters
      if (attesters.length) {
        DB.queues.tasks.shift()
        task.attester = attester.id
        book({ type: fnName, selectedProviders: attesters, role: 'attester', task_id, log })
        log({ type: 'storage', data: { text: 'Booked attester', task: task_id } })
        book({ type: fnName, selectedProviders: [{id: hoster_id}], role: 'hoster', task_id, log })
        log({ type: 'storage', data: { text: 'Booked hoster', task: task_id } })
        
        DB.active.storageChallenges[task_id] = true
        const sid = scheduleAction({ from: log, data: {user}, delay: 5, type: 'storage_challenge_timeout' })
        const timestamp = performance.now()
        user.hoster.challenge = { status: 'active', timestamp, sid, cid: task_id }
        // emit event
        log({ type: 'chain', data: [fnName, task_id] })
        emitEvent(fnName, [task_id], log)
      } else {
        DB.queues.tasks.shift()
        temp_queue.push(next)
      }
    }
    else if (fnName === 'performanceChallenge' && DB.status.idleAttesters.length) {
      // TODO: schedule timeout
      const performanceChallenge = task
      const { feed: feedID, id } = performanceChallenge
      const feedObj = getFeedByID(feedID)
      const hostersForChallenge = []
      for (const contractID of feedObj.contracts) {
        const contract = getContractByID(contractID)
        if (contract.status === 'cancelled') continue
        const { amendments } = contract 
        const active_amendment = getAmendmentByID(amendments[amendments.length-1])
        const { providers: { hosters }} = active_amendment
        for (const id of hosters) avoid[id] = true
        const not_paused = hosters.filter(id => !getUserByID(id).status.paused)
        hostersForChallenge.push(...not_paused)
      }
      log({ type: 'chain', data: { text: 'performance challenge (next task)', hostersForChallenge, task_id } })
      if (!hostersForChallenge.length) {
        log({ type: 'chain', data: { text: 'Error: there is no hoster active for this feed in next task', feedID, challenge_id: id } })
        DB.queues.tasks.shift()
        temp_queue.push(next)
        return // if all hosters are paused (no challenge) => this should never happen
      }
      performanceChallenge.hosters = [...new Set(hostersForChallenge)]
      const idleProviders = DB.status.idleAttesters
      const attesters = select({ idleProviders, role: 'attester', amount: 1, avoid, plan: {}, log })
      if (!attesters.length) {
        log({ type: 'chain', data: { text: 'Error: there is no attesters avail for performance challenge', feedID, task_id } })
        DB.queues.tasks.shift()
        temp_queue.push(next)
        return 
      }
      DB.queues.tasks.shift()
      performanceChallenge.attesters = attesters.map(provider => provider.id)
      book({ type: fnName, selectedProviders: attesters, role: 'attester', task_id, log })
      const selectedHosters = performanceChallenge.hosters.map(id => ({ id, role: 'hoster' }))
      book({ type: fnName, selectedProviders: selectedHosters, role: 'hoster', task_id, log })
      log({ type: 'chain', data: [fnName, task_id] })      
      
      DB.active.performanceChallenges[task_id] = true
      const sid = scheduleAction({ from: log, data: {feedID}, delay: 5, type: 'performance_challenge_timeout' })
      feedObj.challenge = { status: 'active', timestamp: performance.now(), sid, cid: task_id }

      // emit event
      emitEvent(fnName, [task_id], log)
    }
    else if (fnName === 'hosterReplacement' || fnName === 'retry_hosterReplacement' && DB.status.idleAttesters.length && DB.status.idleEncoders.length && DB.status.idleHosters.length) { 
      const { providers, positions, contract: contractID } = task
      const { plan: planID } = getContractByID(contractID)
      const plan = getPlanByID(planID)

      // add old providers to the avoid
      for (var i = 0; i < providers.encoders.length; i++) {
        if (positions.includes(i)) continue // same encoder can be reused, they didn't fail
        avoid[providers.encoders[i]] = true
      }
      for (var i = 0; i < providers.hosters.length; i++) {
        avoid[providers.hosters[i]] = true // failed hoster + active hosters can not be reused
      }
      
      // find providers (x encoders, 1 attester, x hosters)
      const [attester] = select({ idleProviders: DB.status.idleAttesters, role: 'attester', amount: 1, avoid, plan, log })
      if (!attester) return log({ type: 'chain', data: [`missing attester`] })
      task.providers.attesters = [attester.id]
      avoid[attester.id] = true
      
      const amount = positions.length

      const encoders = select({ idleProviders: DB.status.idleEncoders, role: 'encoder', amount, avoid, plan, log })
      if (!encoders.length) return log({ type: 'chain', data: [`missing encoders`] })
      for (var i = 0; i < amount; i++) {  
        const encoder = encoders[i]
        const pos = positions[i]
        task.providers.encoders[pos] = encoder.id
        avoid[encoder.id] = true
      }
    
      const hosters = select({ idleProviders: DB.status.idleHosters, role: 'hoster', amount, avoid, plan, log })
      if (!hosters.length) return log({ type: 'chain', data: [`missing hosters`] })
      for (var i = 0; i < amount; i++) {   
        const hoster = hosters[i]
        const pos = positions[i]
        task.providers.hosters[pos] = hoster.id
        avoid[hoster.id] = true
      }
      
      // book only replacement encoders, all hosters and all (one) attester
      book({ type: fnName, selectedProviders: encoders, role: 'encoder', task_id, log })
      book({ type: fnName, selectedProviders: task.providers.hosters.map(id => ({ id })), role: 'hoster', task_id, log })
      book({ type: fnName, selectedProviders: [attester], role: 'attester', task_id, log })
      
      log({ type: 'chain', data: { 
        text: 'got providers for hosterReplacement', 
        hosters: task.providers.hosters,
        encoders: task.providers.encoders,
        avoid: Object.keys(avoid),
        positions,
        amendment: JSON.stringify(getAmendmentByID(task_id))
      } })
      
      DB.queues.tasks.shift()
      
      // emit event
      log({ type: 'chain', data: [fnName, task_id] })
      emitEvent(fnName, [task_id], log)

      task.sid = scheduleAction({ from: log, data: { id: task_id }, delay: 5, type: 'hoster_replacement_timeout' })
    }
  }
  DB.queues.tasks.push(...temp_queue)
}

async function trigger_challenges ({ hosters, contractID, amendmentID, feedObj, log}) {
  for (var i = 0, len = hosters.length; i < len; i++) {
    const user = getUserByID(hosters[i])
    const tasks = Object.keys(user.hoster.tasks).map(task => Number(task))
    log(`Hosting started: hoster: ${hosters[i]}, contract: ${contractID}, amendment: ${amendmentID}, tasks: ${tasks}, challenge: ${JSON.stringify(user.hoster.challenge)}, feedObj_challenge: ${feedObj.challenge.status}`)
    
    // change task from hostingSetup/retry_hostingSetup to just hosting
    user.hoster.tasks[amendmentID] = 'hosting'

    // schedule storage challenges (for each hoster only once) 
    // TODO: improve, because if one hoster hosts a lot, they won't be challenged enough
    if (!user.hoster.challenge.status) {
      await cleanup_and_new_storage_challenge({ user, log })
    }
  }
  
  // schedule performance challenge
  if (!feedObj.challenge.status) {
    feedObj.challenge.status = 'pending'
    await cleanup_and_new_performance_challenge(feedObj.id, log)
  }
}

function cancelContracts (plan, log) {
  const contracts = plan.contracts
  for (var i = 0; i < contracts.length; i++) {
    const contractID = contracts[i]
    const contract = getContractByID(contractID)
    if (contract.status === 'cancelled') return
    contract.status = 'cancelled'
    const amendments = contract.amendments
    const active_amendment = getAmendmentByID(amendments[amendments.length-1])
    const { id: amendmentID, providers: { hosters } } = active_amendment
    log({ type: 'chain', data: { text: `Cancel contracts`, contractID, amendmentID } })
    for (const id of hosters) {
      // TODO: ACTION find new provider for the contract (makeAmendment(reuse))
      ({ amendmentID, userID: id, type: 'hosting', status: 'cancel', log })
    }
  }
}

function get_random_ids ({items, max}) {
  if (items.length < max) return items
  const selected = []
  while (selected.length < max) {
    const pos = Math.floor(Math.random() * items.length)
    if (!selected.includes(pos)) selected.push(pos)
  }
  return selected.map(pos => items[pos])
}

// TODO:
// performance challenge 
  // group all challenges for same feed (all through same swarm) -> feed has many hosters (feed.contracts)
// storage challenge - group all challenges for same hoster (all through same beam connection) -> hoster hosts many feeds (user.hoster.tasks[amendmentID])

async function planValid ({ plan }) {
  const blockNow = header.number
  const { duration: { from, until } } = plan
  if ((until > from) && ( until > blockNow)) return true
}

async function _retry_amendment ({ failed, amendmentID, log }) {
  emitEvent('hostingSetup_failed', [amendmentID], log)
  const task = amendmentID
  const amendment = getAmendmentByID(amendmentID)
  const { providers: { hosters, attesters, encoders }, contract: contractID } = amendment
  log({ type: 'chain', data: { text: 'Retrying amendment', failed, attesters, encoders, hosters, amendmentID } })
  
  for (const id of hosters) {
    const user = getUserByID(id)
    if (failed.includes(id)) {
      _pause({ args: { status: 'fail', log }, user })
      unbook_and_rate({ id, role: 'hoster', task, type: 'hostingSetup', status: 'fail', log })
    } else {
      unbook_and_rate({ id, role: 'hoster', task, type: 'hostingSetup', status: 'unknown', log })
    }
  }
  
  for (const id of encoders) {
    const user = getUserByID(id)
    if (failed.includes(id)) {
      _pause({ args: { status: 'fail', log }, user })
      unbook_and_rate({ id, role: 'encoder', task, type: 'hostingSetup', status: 'fail', log })
    } else {
      unbook_and_rate({ id, role: 'encoder', task, type: 'hostingSetup', status: 'unknown', log })
    }
  }
  
  for (const id of attesters) {
    const user = getUserByID(id)
    if (failed.includes(id)) {
      _pause({ args: { status: 'fail', log }, user })
      unbook_and_rate({ id, role: 'attester', task, type: 'hostingSetup', status: 'fail', log })
    } else {
      unbook_and_rate({ id, role: 'attester', task, type: 'hostingSetup', status: 'unknown', log })
    }
  }

  // TODO: add new amendment to contract only after it is taken from the queue
  // make new amendment
  const type = 'retry_hostingSetup'
  // TODO: implement reuse logic, for now we just start from scratch
  const providers = { encoders: [], attesters: [], hosters: [] }
  const newID = await init_amendment({ contractID, providers, type, log })
  log({ type: 'chain', data: { text: 'Retry amendment', newID } })
  DB.queues.tasks.push({ fnName: type, id: newID }) // TODO: sort tasks based on priority (RATIO!)
  next_task(log)
}

function isValidHoster ({ hosters, failedHosters, hosterID }) {
  // is hoster listed in the amendment for hosting and is hoster not listed as failed (by the attester)
  if (!hosters.includes(hosterID) || failedHosters.includes(hosterID)) return log({ type: 'chain', data: [`Error: this user can not call this function`] })
  return true
}

function emitEvent (method, data, log) {
  const message = [{ event: { data, method } }]
  eventpool.push([log, message])
  log({ type: 'chain', data: { text: 'new event emitted', method, data } })
}

function get_datasets (plan) {
  const dataset_ids = plan.program.map(item => item.dataset).flat()
  return dataset_ids.map(id => getDatasetByID(id))
}

function getBlockNumber () {
  return header.number
}