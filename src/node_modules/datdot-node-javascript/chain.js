const varint = require('varint')
const WebSocket = require('ws')

const { performance } = require('perf_hooks')

const datdot_crypto = require('datdot-crypto')
const logkeeper = require('datdot-logkeeper')
const storage_report_codec = require('datdot-codec/storage-report')

const makeSets = require('_makeSets')
const PriorityQueue = require('_priority-queue')

const DB = require('./DB')
const blockgenerator = require('./scheduleAction.js')


const priority_queue = PriorityQueue(compare)
function compare (item) { return item }
const blockinterval = 5000 // in miliseconds
var header = { number: 0 }
const scheduler = init()
const connections = {}
var eventpool = []
var mempool = []


async function init () {
  const [json, logport] = process.argv.slice(2)
  const config = JSON.parse(json)
  const [host, PORT] = config.chain
  const name = `chain`
  const log = await logkeeper(name, logport)
  const wss = new WebSocket.Server({ port: PORT }, after)
  function after () {
    log({ type: 'info', data: `running on http://localhost:${wss.address().port}` })
  }
  const scheduler = blockgenerator({ blockinterval, intrinsics }, log.sub('blockgenerator'), async blockMessage => {
    const { number, startTime } = blockMessage.data
    const currentBlock = header.number = number
    const temp = [...mempool]
    mempool = []
    try {
      while (temp.length) {
        if ((performance.now() - startTime) < (blockinterval - 200)) {
          const extrinsic = temp.shift() // later take out the ones which offers highest gas
          await extrinsic()
        } else {
          const text = `not able to execute the remaining ${temp.length} extrinsics in mempool during blockinterval`
          log({ type: 'warn', data: text })
          mempool = [...temp, ...mempool]
          emitBlock()
          return
        }
      }
      emitBlock()
    } catch (error) {
      const stack = error.stack
      log({ type: 'fail', data: { text: 'failed-mempool', stack } })
    }
    async function emitBlock () {
      log({ type: 'eventpool', data: { text: `event pool in emitBlock`, data: eventpool } })
      const temp_pool = [...eventpool]
      eventpool = []
      temp_pool.forEach(([log, message]) => {
        log({ type: 'info', data: { text: `emit chain event`, data: JSON.stringify(message) } })
      })
      const promises = Object.entries(connections).map(([name, { ws, handler }]) => new Promise((resolve, reject) => {
        ws.send(JSON.stringify(blockMessage))
        temp_pool.forEach(([log, message]) => { handler(message) })
        resolve()
      }))
      await Promise.all(promises)
      log({ type: 'current-block', data: currentBlock })
    }
  })
  wss.on('connection', function connection (ws) {
    ws.on('message', async function incoming (message) {
      var { flow, type, data } = JSON.parse(message)
      const [from, id] = flow
      log({ type: 'extrinsic', data: { type, flow } })

      const method = queries[type]
      if (method) {
        const result = await method(data, from, data => {
          // _log({ type: 'info', data: [`send data after "${type}" to: ${from}`] })
          ws.send(JSON.stringify({ cite: [flow], type: 'data', data }))
        })
        if (!result) return
        const msg = { cite: [flow], type: 'done', data: result }
        // _log({ type: 'info', data: [`sending "${type}" to: ${from}`] })
        return void ws.send(JSON.stringify(msg))
      }

      if (!connections[from] && DB.lookups.userByAddress[data.address]) {
        const userlog = log.sub(from)
        connections[from] = { name: from, counter: 0, ws, log: userlog, handler: data => ws.send(JSON.stringify({ data })) }
      }

      if (id === 0 && type === 'newUser') {
        mempool.push(() => makeNewUser(data, from, ws))// a new connection
      } else {
        mempool.push(() => signAndSend(type, flow, data, from, data => {
          // _log({ type: 'info', data: [`send data after "${type}" to: ${from}`] })
          ws.send(JSON.stringify({ cite: [flow], type: 'data', data }))
        }))
      }
    })
    ws.on('open', function open () {
      log('======= OPEN =======')
    })
    ws.on('error', function error (err) {
      log('======= OPEN =======')
      log(err)
    })
    ws.on('close', function close () {
      log('[ERROR] unexpected closing of chain connection for', name)
    })
  })
  /******************************************************************************
    ROUTING (sign & send)
  ******************************************************************************/
  async function signAndSend (msgtype, flow, data, name, status) {
    const { log, ws } = connections[name]
    log({ type: 'execute-extrinsic', data: msgtype })

    try {
      if (msgtype === 'submitStorageChallenge') data = storage_report_codec.decode(data, log)
      const { type, args, nonce, address } = data
      
      status({ events: [], status: { isInBlock:1 } })
      
      const user = await _getUser(address, { name, nonce }, status)
      if (!user) return void log({ type: 'info', data: [`UNKNOWN SENDER of: ${data}`] }) // TODO: maybe use status() ??

      else if (type === 'publishPlan') _publish_plan(user, { name, nonce }, status, args)
      else if (type === 'registerForWork') _register_for_work(user, { name, nonce }, status, args)
      else if (type === 'amendmentReport') _amendment_report(user, { name, nonce }, status, args)
      else if (type === 'submitStorageChallenge') _storage_challenge_report(user, { name, nonce }, status, args)
      else if (type === 'submitPerformanceChallenge') _submitPerformanceChallenge(user, { name, nonce }, status, args)
      // else if ...
      else ws.send(JSON.stringify({ cite: [flow], type: 'error', data: 'unknown type' }))
    } catch (error) {
      log({ type: 'fail', data: { type: msgtype, error } })
    }
  }
  /******************************************************************************
   MAKE NEW USER
  ******************************************************************************/
  async function makeNewUser (data, from, ws) {
    const { args, nonce, address } = data
    // 1. do we have that user in the database already?
    if  (from && address && !connections[from] && !DB.lookups.userByAddress[address]) {
      const userlog = log.sub(from)
      connections[from] = { name: from, counter: 0, ws, log: userlog, handler: data => ws.send(JSON.stringify({ data })) }
      // @TODO: ...
      if (!messageVerifiable(data)) return // TODO: verify MICRO PROOF OF WORK
      _newUser(args, from, address, userlog)
      // 2. is the message verifiable, pubkeys, noisekeys, signatures?
      // 3. => add user and address and user data to database
    }
    else return ws.send(JSON.stringify({
      cite: [flow], type: 'error', data: 'name is already taken'
    }))
    // return
  }
  return scheduler
}

function messageVerifiable (message) {
  return true
}
/******************************************************************************
  QUERIES
******************************************************************************/
const queries = {
  getItemByID,
  getFeedByID,
  getFeedByKey,
  getUserByID,
  getUserIDByNoiseKey,
  getUserIDBySigningKey,
  getPlanByID,
  getAmendmentByID,
  getContractByID,
  getStorageChallengeByID,
  getPerformanceChallengeByID,
}

// function getFeedByID (id) { return DB.feeds[id] }
// function getUserByID (id) { return DB.users[id] }
// function getPlanByID (id) { return DB.plans[id] }
// function getContractByID (id) { return DB.contracts[id] }
// function getAmendmentByID (id) { return DB.amendments[id] }
// function getStorageChallengeByID (id) { return DB.storageChallenges[id] }
// function getPerformanceChallengeByID (id) { return DB.performanceChallenges[id] }
function getItemByID (id) { return getItem(id) }
function getDatasetByID (id) { return getItem(id) }
function getFeedByID (id) { return getItem(id) }
function getUserByID (id) { return getItem(id) }
function getPlanByID (id) { return getItem(id) }
function getContractByID (id) { return getItem(id) }
function getAmendmentByID (id) { return getItem(id) }
function getStorageChallengeByID (id) { return getItem(id) }
function getPerformanceChallengeByID (id) { return getItem(id) }
// ---
function getFeedByKey (key) {
  const keyBuf = Buffer.from(key, 'hex')
  return DB.lookups.feedByKey[keyBuf.toString('hex')]
}
function getUserIDByNoiseKey(key) {
  const keyBuf = Buffer.from(key, 'hex')
  return DB.lookups.userIDByNoiseKey[keyBuf.toString('hex')]
}
function getUserIDBySigningKey(key) {
  const keyBuf = Buffer.from(key, 'hex')
  return DB.lookups.userIDBySigningKey[keyBuf.toString('hex')]
}
/******************************************************************************
  SCHEDULABLE INTRINSICS
******************************************************************************/
const intrinsics = { 
  plan_execution, 
  amendment_timeout, 
  make_storage_challenge, 
  make_performance_challenge, 
  storage_challenge_timeout,
  performance_challenge_timeout,
 }

async function plan_execution (log, data) {
  const { contract_id } = data
  const reuse = { encoders: [], attestors: [], hosters: [] }
  const amendment_id = await init_amendment(contract_id, reuse, log)
  log({ type: 'info', data: { text: 'Plan execution', contract_id, amendment_id } })
  DB.queues.tasks.push({ fnName: 'amendment', id: amendment_id }) // TODO sort tasks based on priority (RATIO!)
  next_task(log)
}

async function storage_challenge_timeout (log, data) {
  const { user } = data
  var { status, timestamp, cid } = user.hoster.challenge
  user.hoster.challenge.status = 'timed-out'
  log({ type: 'storage-challenge-timeout', data: { status, cid, perf: performance.now() - timestamp} })
  const storageChallenge = getStorageChallengeByID(cid)
  const attestorID = storageChallenge.attestor
  remove_task({ id: attestorID, role: 'attestor', task: cid, idleProviders: DB.status.idleAttestors, status: 'fail', log })
  evaluate_storage_challenge_report({ storageChallenge, reports: [], log })
  await start_new_storage_challenge(user, log)
}

async function performance_challenge_timeout (log, data) {
  const { feedID } = data
  const feed = getFeedByID(feedID)
  const { status, timestamp, cid } = feed.challenge
  feed.challenge.status = 'timed-out'
  log({ type: 'performance-challenge-timeout', data: { status, cid, perf: performance.now() - timestamp} })
  const performanceChallenge = getPerformanceChallengeByID(cid)
  const attestorIDs = performanceChallenge.attestors
  attestorIDs.forEach(id => remove_task({ id, role: 'attestor', task: cid, idleProviders: DB.status.idleAttestors, status: 'fail', log }))
  // evaluate_performance_challenge_report({ id: cid, reports: [], log })
  await start_new_performance_challenge(feedID, log)
}

async function amendment_timeout (log, data) {
  const { id } = data
  log({ type: 'info', data: { text: 'Amendment timed out', id } })
  const { providers: { attestors, hosters, encoders } } = getAmendmentByID(id)
  const failed = [...attestors, ...hosters, ...encoders]
  _retry_amendment({ failed, amendmentID: id, log})
}

async function make_storage_challenge (log, data) {
  const hoster_id = data.hoster_id
  const { scheduleAction } = await scheduler
  // select an attestor
  // tell them which hoster to challenge
  // tell them which subset of contracts & chunks to challenge
  const user = getUserByID(hoster_id)
  const tasks = Object.keys(user.hoster.tasks).map(task => Number(task))
  if (!tasks.length) return
  const contracts_ids = tasks.map(id => getAmendmentByID(id).contract)
  const selected = get_random_ids({ items: contracts_ids, max: 5 })
  const checks = {}
  const avoid = {}
  for (var i = 0, len = selected.length; i < len; i++) {
    const contractID = selected[i]
    const { plan, ranges } = getContractByID(contractID)
    avoid[plan.sponsor] = true
    checks[contractID] = { index: getRandomChunk(ranges) }
  }
  const storage_challenge = { checks, hoster: hoster_id }
  const id = addItem(storage_challenge)
  DB.active.storageChallenges[id] = true
  // find & book the attestor
  const type = 'NewStorageChallenge'
  avoid[hoster_id] = true
  const idleProviders = DB.status.idleAttestors
  const selectedProviders = select({ idleProviders, role: 'attestor', newTask: id, amount: 1, avoid, plan: {}, log })
  const [attestor] = selectedProviders
  if (!attestor) return DB.queues.tasks.push({ fnName: 'NewStorageChallenge', id })
  storage_challenge.attestor = attestor.id
  start_task({ type, selectedProviders, idleProviders, role: 'attestor', newTask: id, log })
  //
  log({ type: 'info', data: { text: 'Making new storage challenge for', items: { type, newTask: id, hoster_id, tasks, cid: id } } })
  user.hoster.challenge = {
    status: 'active',
    timestamp: performance.now(),
    sid: scheduleAction({ from: log, data: {user}, delay: 2, type: 'storage_challenge_timeout' }), 
    cid: id 
  }
  // emit event
  emitEvent(type, [id], log)
}

async function make_performance_challenge (log, data) {
  const { feedID } = data
  const { scheduleAction } = await scheduler
  const feed = getFeedByID(feedID)
  const contractIDs = feed.contracts

  const performanceChallenge = { feed: feedID }
  const id = addItem(performanceChallenge)
  performanceChallenge.id = id
  DB.active.performanceChallenges[id] = true
  
  // find attestors
  const avoid = {}
  for (var i = 0, len = contractIDs.length; i < len; i++) {
    const { amendments, plan: planID } = getContractByID(contractIDs[i])
    const plan = getPlanByID(planID)
    avoid[plan.sponsor] = true
    const active_amendment = getAmendmentByID(amendments[amendments.length-1])
    const hosterIDs = active_amendment.providers.hosters
    hosterIDs.forEach(id => avoid[id] = true)
  }
  const type = 'NewPerformanceChallenge'
  const idleProviders = DB.status.idleAttestors
  const attestors = select({ idleProviders, role: 'attestor', newTask: id, amount: 1, avoid, plan: {}, log })
  if (!attestors.length) return DB.queues.tasks.push({ fnName: 'NewPerformanceChallenge', id })
  performanceChallenge.attestors = attestors.map(attestor => attestor.id)
  start_task({ type, selectedProviders: attestors, idleProviders, role: 'attestor', newTask: id, log })
  log({ type: 'challenge', data: {text:'Making new performance chalenge', items: {challenge: type, newTask: id, attestors, cid: id} }})
  feed.challenge = {
    status: 'active',
    timestamp: performance.now(),
    sid: scheduleAction({ from: log, data: {feedID}, delay: 2, type: 'performance_challenge_timeout' }), 
    cid: id 
  }
  // emit event
  log({ type: 'info', data: [type, id] })
  emitEvent(type, [id], log)
}

/******************************************************************************
  API
******************************************************************************/
async function _getUser (address, { name, nonce }, status) {
  const log = connections[name].log
  const pos = DB.lookups.userByAddress[address]
  const user = getUserByID(pos)
  log({ type: 'info', data: `Existing user: ${name}, ${user.id}, ${address}` })
  return user
}

/*----------------------
      STORE ITEM
------------------------*/
function addItem (item) {
  if ('id' in item) throw new Error('new items cannot have "id" property')
  const id = DB.storage.length
  item.id = id
  DB.storage.push([item])
  return id
}
function getItem (id) {
  if (!Number.isInteger(id)) return
  if (id < 0) return
  const len = DB.storage.length
  if (id >= len) return
  const history = DB.storage[id]
  if (!Array.isArray(history)) return
  const next = history.length
  const item = history[next - 1]
  return item
}
function delItem (id) {
  if (!Number.isInteger(id)) return
  if (id < 0) return
  const len = DB.storage.length
  if (id >= len) return
  const history = DB.storage[id]
  if (!Array.isArray(history)) return
  return !!history.push(void 0)
}
function updateItem (id, item) {
  if (!Number.isInteger(id)) return
  if (id < 0) return
  const len = DB.storage.length
  if (id >= len) return
  const history = DB.storage[id]
  if (!Array.isArray(history)) return
  return !!history.push(item)
}

/*----------------------
      NEW USER
------------------------*/
async function _newUser (args, name, address, log) {
  let [data] = args
  const { signingPublicKey, noiseKey } = data

  const user = { address }
  addItem(user)
  DB.lookups.userByAddress[address] = user.id
  log({ type: 'info', data: [`New user: ${name}, ${JSON.stringify(user)}`] })

  user.signingKey = signingPublicKey
  const signingKeyBuf = Buffer.from(signingPublicKey, 'hex')
  DB.lookups.userIDBySigningKey[signingKeyBuf.toString('hex')] = user.id

  user.noiseKey = noiseKey
  const noiseBuf = Buffer.from(noiseKey, 'hex')
  DB.lookups.userIDByNoiseKey[noiseBuf.toString('hex')] = user.id
}

/*----------------------
      REGISTER FOR WORK
------------------------*/
async function _register_for_work (user, { name, nonce }, status, args) {
  const log = connections[name].log
  let [form] = args
  const { components } = form
  const { resources_ids, performances_ids, timetables_ids, regions_ids } = await publish_form_components(components)

  form.timetables = form.timetables.map(ref => { if (ref < 0) return timetables_ids[(Math.abs(ref) - 1)] })
  form.regions = form.regions.map(ref => { if (ref < 0) return regions_ids[(Math.abs(ref) - 1)] })
  form.performances = form.performances.map(ref => { if (ref < 0) return performances_ids[(Math.abs(ref) - 1)] })
  form.resources = form.resources.map(ref => { if (ref < 0) return resources_ids[(Math.abs(ref) - 1)] })
  user.form = form
  user.idleStorage = getItem(form.resources[0]).storage
  log({ type: 'register', data: [`Registering for work`] })
  ;['encoder', 'hoster', 'attestor'].forEach(role => registerRole (user, role, log))
}

/*----------------------
      PUBLISH FEED
------------------------*/
// TODO:
// * we wont start hosting a plan before the check
// * 3 attestors
// * provide signature for highest index in ranges
// * provide all root hash sizes required for ranges
// => native api feed.getRoothashes() provides the values

/*----------------------
      (UN)PUBLISH PLAN
------------------------*/
async function _publish_plan (user, { name, nonce }, status, args) {
  const log = connections[name].log
  log({ type: 'info', data: [`Publishing a plan`] })
  let [data] = args
  const { plan, components, proofs = {}  } = data
  const { program } = plan
  const feed_ids = await Promise.all(components.feeds.map(async feed => await publish_feed(feed, user.id, log)))
  store_root_signatures(proofs, feed_ids, log)
  const component_ids = await publish_plan_components(log, components, feed_ids)

  const updated_program = []
  for (var i = 0, len = program.length; i < len; i++) {
    const item = program[i]
    if (item.plans) updated_program.push(...getPrograms(item.plan))
    else updated_program.push(handleNew(item, component_ids))
  }
  plan.program = updated_program
  if (!planValid({ plan })) return log({ type: 'info', data: [`Plan from and/or until are invalid`] })
  plan.sponsor = user.id

  plan.contracts = []
  const id = addItem(plan)

  priority_queue.add({ type: 'plan', id })
  take_next_from_priority(priority_queue.take(), log) // schedule the plan execution
}

async function unpublishPlan (user, { name, nonce }, status, args) {
  const [planID] = args
  const plan = getPlanByID(planID)
  if (!plan.sponsor === user.id) return log({ type: 'info', data: [`Only a sponsor is allowed to unpublish the plan`] })
  cancelContracts(plan) // remove all hosted and draft contracts
}
/*----------------------
  (UN)REGISTER ROLES
------------------------*/
async function registerRole (user, role, log) {
  const userID = user.id
  // registered.push(role)
  if (!user[role]) {
    user[role] = {
      tasks: {},
      challenge: {},
      capacity: 5, // TODO: calculate capacity for each task based on the form
    }
  }
  const first = role[0].toUpperCase()
  const rest = role.substring(1)
  DB.status[`idle${first + rest}s`].push(userID)
  next_task(log)
}

/*----------------------
  AMENDMENT REPORT
------------------------*/
async function _amendment_report (user, { name, nonce }, status, args) {
  const log = connections[name].log
  const meta = [user, name, nonce, status]
  const [ report ] = args
  const { id: amendmentID, failed, signatures } = report // [2,6,8]
  const amendment = getAmendmentByID(amendmentID)
  const { providers: { hosters, attestors, encoders }, contract: contractID, sid } = amendment
  const contract = getContractByID(contractID)
  const plan = getPlanByID(contract.plan)
  const feed = getFeedByID(contract.feed)
  const [attestorID] = attestors
  // check if right attestor
  if (user.id !== attestorID) return log({ type: 'info', data: [`Error: this user can not submit the attestation, ${JSON.stringify(attestors)}, ${user.id}`] })
  // check if right amendment
  if (contract.amendments[contract.amendments.length - 1] !== amendmentID) return log({ type: 'info', data: [`Error: this amendment has expired`] })
  // cancel amendment schedule
  const { cancelAction } = await scheduler
  if (!amendment.sid) log({ type: 'info', data: { text: 'No scheduler for', contract } })
  cancelAction(amendment.sid)
  // verify hosters' signatures
  for (var i = 0, len = hosters.length; i < len; i++) {
    const hoster_id = hosters[i]
    if (failed.includes(hoster_id)) continue
    const sig = signatures[hoster_id]
    const data = Buffer.from(`${amendmentID}/${i}`, 'binary')
    const { signingKey }  = getUserByID(hoster_id)
    if (!sig_verified(sig, data, signingKey)) return log({ type: 'info', data: [`Error: unique_el_signature for hoster: ${hoster_id} could not be verified`] })
  }
  log({ type: 'info', data: [`amendmentReport hoster signatures verified`] })
  
  if (failed.length) _retry_amendment({ failed, amendmentID, log })
  else {
    feed.contracts.push(contractID)
    encoders.forEach(id => remove_task({ id, role: 'encoder', task: amendmentID, idleProviders: DB.status.idleEncoders, status: 'done', log }))
    attestors.forEach(id => remove_task({ id, role: 'attestor', task: amendmentID, idleProviders: DB.status.idleAttestors, status: 'done', log }))
    
    for (var i = 0, len = hosters.length; i < len; i++) {
      const user = getUserByID(hosters[i])
      const tasks = Object.keys(user.hoster.tasks).map(task => Number(task))
      log(`Hosting started: contract: ${contractID}, amendment: ${amendmentID}, hoster: ${hosters[i]}, tasks: ${tasks}, challenges: ${JSON.stringify(user.hoster.challenge)}`)
      // schedule storage challenges (for each hoster only once)
      if (!user.hoster.challenge.status) {
        user.hoster.challenge.status = 'pending'
        await start_new_storage_challenge(user, log)
      }
    }
    // schedule performance challenge
    if (!feed.challenge.status) {
      feed.challenge.status = 'pending'
      await start_new_performance_challenge(feedID, log)
    }

    // => until HOSTING STARTED event, everyone keeps the data around
    emitEvent('HostingStarted', [amendmentID], log)
    return
  }
}


/*----------------------
  STORAGE CHALLENGE
------------------------*/

async function _storage_challenge_report (attestor, { name, nonce }, status, args) {
  const log = connections[name].log
  const [ response ] = args
  const { reports, storage_challenge_signature, storageChallengeID } = response
  const storageChallenge = getStorageChallengeByID(storageChallengeID)
  const { attestor: attestorID, hoster: hosterID } = storageChallenge
  const user = getUserByID(hosterID)
  var { status, cid, sid } = user.hoster.challenge
  const messageBuf = Buffer.alloc(varint.encodingLength(storageChallengeID))
  varint.encode(storageChallengeID, messageBuf, 0)
  const signingKeyBuf = Buffer.from(user.signingKey, 'binary')
  const info_msg = { type: 'info', data: { text: `Received StorageChallenge`, storageChallengeID, fields: Object.keys(response), status, cid, sid } }
  log(info_msg)

  // verify attestor
  if (attestor.id !== attestorID) {
    user.hoster.challenge.status = 'fail'
    await start_new_storage_challenge(user, log)
    return log({ type: 'challenge fail', data: [`Only the attestor can submit this storage challenge`] })
  }
  // TODO: attestor finished task, add them to idleAttestors again
  remove_task({ id: attestorID, role: 'attestor', task: storageChallengeID, idleProviders: DB.status.idleAttestors, status: 'done', log })
  // verify hoster signed the event
  if (!datdot_crypto.verify_signature(storage_challenge_signature, messageBuf, signingKeyBuf)) {
    challenge.status = 'fail'
    await start_new_storage_challenge(user, log)
    return log({ type: 'challenge fail', data: [`Storage challenge failed ${storageChallengeID}`] })
  }
  // verify challengeID
  if (user.hoster.challenge.cid !== storageChallengeID) {
    user.hoster.challenge.status = 'fail'
    await start_new_storage_challenge(user, log)
    return log({ type: 'challenge fail', data: `Not an active storage challenge: CID ${cid}/ID ${storageChallengeID} }` })
  }
  // evaluate report
  evaluate_storage_challenge_report({ storageChallenge, reports, log })
  user.hoster.challenge.status = 'done'
  log({ type: 'challenge done', data: `Storage challenge confirmed ${JSON.stringify(user.hoster.challenge)}` })
  // new challenge
  await start_new_storage_challenge(user, log)
}

function  evaluate_storage_challenge_report ({ storageChallenge, reports, log }) {
  const { checks, id: storageChallengeID } = storageChallenge
  if (!reports.length) return log({ type: 'info', data: [`This reports for storage challenge ${storageChallengeID} are empty`] })
  // If timeout reports will be empty [] - TODO make timeout default reports
  // TODO if attestor failed => rating reduced
  // TODO also call this in regular storage_report
  // TODO reward (update account balances) and adjust rating for all users

  for (var i = 0, len = reports.length; i < len; i++) {
    const { contractID, version, nodes } = reports[i]
    const check = checks[contractID]
    if (!check) return log('error, there is no check for this contractID')
    const { feed: feedID } = getContractByID(contractID)
    const { feedkey, signatures } = getFeedByID(feedID)
    const index = check.index
    const signatureBuf = Buffer.from(signatures[version], 'binary')
    const keyBuf = Buffer.from(feedkey, 'hex')
    const not_verified = datdot_crypto.merkle_verify({
      feedKey: keyBuf, 
      hash_index: index * 2, 
      version, 
      signature: signatureBuf, 
      nodes
    })
    if (not_verified) return log({ type: 'info', data: `This report can not be verified` })
    log({ type: 'info', data: { text: 'storage confirmed', contractID, hosterID: storageChallenge.hoster, check } })
  }
}

async function start_new_storage_challenge (user, log) {
  var { status, cid, sid } = user.hoster.challenge
  log({ type: 'info', data: { text: 'Start new storage challenge', items: { hosterID: user.id, status, cid, sid } } })
  const { scheduleAction, cancelAction } = await scheduler
  if (status === 'stop') return
  if (status === 'done' || status === 'timed-out' || status === 'fail') {
    cancelAction(sid) // scheduled action id
    log({ type: 'info', data: {text:'RESET old storage challenge', items: { hosterID: user.id, status, cid, sid } }})
  }
  scheduleAction({ from: log, data: {hoster_id: user.id}, delay: 1, type: 'make_storage_challenge' })
}
/*----------------------
  PERFORMANCE CHALLENGE
------------------------*/
async function start_new_performance_challenge (feedID, log) {
  const { challenge } = getFeedByID(feedID)
  const { status, cid, sid } = challenge
  log({ type: 'info', data: { text: 'Start new performance challenge', items: { feedID, status, cid, sid } } })
  const { scheduleAction, cancelAction } = await scheduler
  if (status === 'stop') return
  if (status === 'done' || status === 'timed-out' || status === 'fail') {
    cancelAction(sid) // scheduled action id
    log({ type: 'info', data: {text:'RESET old performance challenge', items: { hosterID: user.id, status, cid, sid } }})
  }
  scheduleAction({ from: log, data: {feedID}, delay: 1, type: 'make_performance_challenge' })
}

async function _submitPerformanceChallenge (user, { name, nonce }, status, args) {
  const log = connections[name].log
  const [ performanceChallengeID, report ] = args
  const userID = user.id
  log({ type: 'info', data: [`Performance Challenge proof by attestor: ${userID} for challenge: ${performanceChallengeID}`] })
  const performanceChallenge = getPerformanceChallengeByID(performanceChallengeID)
  if (!performanceChallenge.attestors.includes(userID)) return log({ type: 'info', data: [`Only selected attestors can submit this performance challenge`] })
  
  const { stats, signed_event } = report
  // if (!is_valid_signature(signed_event)) return
  var method = report ? 'PerformanceChallengeFailed' : 'PerformanceChallengeConfirmed'
  if (report) log({ type: 'info', data: 'Performance challenge confirmed' })
  emitEvent(method, [performanceChallengeID], log)
  // attestor finished task, add them to idleAttestors again
  remove_task({ id: userID, role: 'attestor', task: performanceChallengeID, idleProviders: DB.status.idleAttestors, status: 'done', log })
}

/******************************************************************************
  HELPERS
******************************************************************************/

const setSize = 10 // every contract is for hosting 1 set = 10 chunks
const size = setSize*64 //assuming each chunk is 64kb
const blockTime = 6000

async function publish_feed (feed, sponsor_id, log) {
  const { feedkey, swarmkey } = feed
  const feedkeyBuf = Buffer.from(feedkey, 'hex')
  const swarmkeyBuf = Buffer.from(swarmkey, 'hex')
  // check if feed already exists
  if (DB.lookups.feedByKey[feedkeyBuf.toString('hex')]) return
  feed = { feedkey: feedkeyBuf.toString('hex'), swarmkey: swarmkeyBuf.toString('hex'), signatures: {}, contracts: [], challenge: {} }
  const feedID = addItem(feed)
  DB.lookups.feedByKey[feedkeyBuf.toString('hex')] = feedID
  feed.publisher = sponsor_id
  emitEvent('FeedPublished', [feedID], log)
  return feedID
}

function store_root_signatures (proofs, feed_ids, log) {
  proofs.map(({ feed_ref, signature, nodes }, i) => {
    const indexes = nodes.map(node => node.index)
    const index = Math.max.apply(Math, indexes)/2 // find highest index/2
    const feed_id = feed_ref < 0 ? feed_ids[(Math.abs(feed_ref) - 1)] : feed_ref
    const feed = getFeedByID(feed_id)
    const feedKey = Buffer.from(feed.feedkey, 'hex')
    signature = Buffer.from(signature, 'binary')
    nodes.forEach(node => {
      node.hash = Buffer.from(node.hash, 'hex')
    })
    const not_verified = datdot_crypto.merkle_verify({feedKey, hash_index: index * 2, version: index, signature, nodes})
    if (not_verified) return log('proof could not be verified')
    feed.signatures[index] = signature
  })
}

async function publish_plan_components (log, components, feed_ids) {
  const { dataset_items, performance_items, timetable_items, region_items } = components
  const dataset_ids = await Promise.all(dataset_items.map(async item => {
    if (item.feed_id < 0) item.feed_id = feed_ids[(Math.abs(item.feed_id) - 1)]
    return addItem(item)
  }))
  const performances_ids = await Promise.all(performance_items.map(async item => addItem(item)))
  const timetables_ids = await Promise.all(timetable_items.map(async item => addItem(item)))
  const regions_ids = await Promise.all(region_items.map(async item => addItem(item)))
  return { dataset_ids, performances_ids, timetables_ids, regions_ids }
} 
async function publish_form_components (components) {
  const {  timetable_items, region_items, performance_items, resource_items } = components
  const timetables_ids = await Promise.all(timetable_items.map(async item => addItem(item)))
  const regions_ids = await Promise.all(region_items.map(async item => addItem(item)))
  const performances_ids = await Promise.all(performance_items.map(async item => addItem(item)))
  const resources_ids = await Promise.all(resource_items.map(async item => addItem(item)))
  return { resources_ids, performances_ids, timetables_ids, regions_ids }
}
function handleNew (item, ids) {
  const keys = Object.keys(item)
  for (var i = 0, len = keys.length; i < len; i++) {
    const type = keys[i]
    item[type] = item[type].map(id => {
      if (id < 0) return ids[`${type}_ids`][(Math.abs(id) - 1)]
    })
  }
  return item
}

function getPrograms (plans) {
  const programs = []
  for (var i = 0; i < plans.length; i++) { programs.push(...plans[i].programs) }
  return programs
}

async function take_next_from_priority (next, log) {
  const plan = await getPlanByID(next.id)
  const contract_ids = await make_contracts(plan, log)
  plan.contracts.push(...contract_ids)
  for (var i = 0, len = contract_ids.length; i < len; i++) {
    const contract_id = contract_ids[i]
    const blockNow = header.number
    const delay = plan.duration.from - blockNow
    const { scheduleAction } = await scheduler
    scheduleAction({ 
      from: log,
      type: 'plan_execution',
      data: { contract_id }, 
      delay,
    })
  }
}

// split plan into sets with 10 chunks
async function make_contracts (plan, log) {
  const dataset_ids = plan.program.map(item => item.dataset).flat()
  const datasets = get_datasets(plan)
  for (var i = 0; i < datasets.length; i++) {
    const feed = getFeedByID(datasets[i].feed_id)
    const ranges = datasets[i].ranges
    // split ranges to sets (size = setSize)
    const sets = makeSets({ ranges, setSize })
    return Promise.all(sets.map(async set => {
      // const contractID = DB.contracts.length
      const contract = {
        plan: plan.id,
        feed: feed.id,
        ranges: set,
        amendments: [],
        activeHosters: [],
        status: {}
       }
      addItem(contract)
      log({ type: 'info', data: [`New Contract: ${JSON.stringify(contract)}`] })
      return contract.id 
    }))
  }
}
// find providers for each contract (+ new providers if selected ones fail)
async function init_amendment (contractID, reuse, log) {
  log('initializing amendment')
  const contract = getContractByID(contractID)
  if (!contract) return log({ type: 'info', data: `No contract with this ID: ${contractID}` })
  log({ type: 'info', data: `Init amendment & find additional providers for contract: ${contractID}` })
  // const id = DB.amendments.length
  const amendment = { contract: contractID }
  // DB.amendments.push(amendment) // @NOTE: set id
  const id = addItem(amendment)
  amendment.providers = reuse
  contract.amendments.push(id)
  return id
}

function getProviders (plan, reused, newTask, log) {
  if (!reused) reused = { encoders: [], attestors: [], hosters: [] }
  const attestorAmount = 1 - (reused.attestors.length || 0)
  const encoderAmount = 3 - (reused.encoders.length || 0)
  const hosterAmount = 3 - (reused.hosters.length || 0)
  const avoid = {}
  avoid[plan.sponsor] = true
  reused.encoders.forEach(id =>  avoid[id] = true)
  reused.attestors.forEach(id =>  avoid[id] = true)
  reused.hosters.forEach(id =>  avoid[id] = true)

  // TODO backtracking!! try all the options before returning no providers available
  const attestors = select({ idleProviders: DB.status.idleAttestors, role: 'attestor', newTask, amount: attestorAmount, avoid, plan, log })
  if (!attestors.length) return log({ type: 'info', data: [`missing attestors`] })
  const encoders = select({ idleProviders: DB.status.idleEncoders, role: 'encoder',  newTask, amount: encoderAmount, avoid, plan, log })
  if (encoders.length !== encoderAmount) return log({ type: 'info', data: [`missing encoders`] })
  const hosters = select({ idleProviders: DB.status.idleHosters, role: 'hoster', newTask, amount: hosterAmount, avoid, plan, log })
  if (hosters.length !== hosterAmount) return log({ type: 'info', data: [`missing hosters`] })

  return {
    encoders: [...encoders, ...reused.encoders],
    hosters: [...hosters, ...reused.hosters],
    attestors: [...attestors, ...reused.attestors]
  }
}
function getRandomIndex(range) {
  const min = range[0]
  const max = range[1]+1
  return Math.floor(Math.random() * (max - min)) + min; //The maximum is exclusive and the minimum is inclusive
}
function getRandomChunk (ranges) { // [[0,3], [5,7]]
  const start = 0
  const end = ranges.length
  const range = ranges[Math.floor(Math.random() * (end - start)) + start]
  return getRandomIndex(range)
}
function select ({ idleProviders, role, newTask, amount, avoid, plan, log }) {
  idleProviders.sort(() => Math.random() - 0.5) // TODO: improve randomness
  const selectedProviders = []
  for (var i = 0; i < idleProviders.length; i++) {
    const id = idleProviders[i]
    if (avoid[id]) continue // if id is in avoid, don't select it
    const provider = getUserByID(id)
    if (doesQualify(plan, provider, role)) {
      selectedProviders.push({id, index: i, role })
      avoid[id] = true
      if (selectedProviders.length === amount) return selectedProviders
    }
  }
  return []
}
function start_task ({ type, selectedProviders, idleProviders, role, newTask, log }) {
  // @NOTE: sortedProviders makes sure those with highest index get sliced first
  // so lower indexes are unchanged until they get sliced too
  const sortedProviders = selectedProviders.sort((a,b) => a.index > b.index ? 1 : -1)
  const providers = sortedProviders.map(({ id, index, role }) => {
    const provider = getUserByID(id)
    provider[role].tasks[newTask] = true
    if (!hasCapacity(provider, role)) idleProviders.splice(index, 1)
    // TODO currently we reduce idleStorage for all providers
    // and for all tasks (also challenge)
    // => take care that it is INCREASED again when task is done
    provider.idleStorage -= size
    return id
  })
  // returns array of selected providers for select function
  return providers
}

// TODO payments: for each successfull hosting we pay attestor(1/3), this hoster (full), encoders (full, but just once)
// async function remove_task ({ providers, taskID }, log) {
//   const task = await getItemByID(taskID)
//   const types = Object.keys(provider)
//   for (var i = 0, ilen = types.length; i < len; i++) {
//     const roles = types[i]//.slice(0, -1)
//     const peerIDs = providers[roles]
//     for (var k = 0, klen = peerIDs.length; k < klen; k++) {
//       const id = peerIDs[k]

//     }
//   }
// }

function remove_task ({ id, role, task, idleProviders, status, log }) {
  const provider = getUserByID(id)
  if (provider[role].tasks[task]) {
    log({ type: 'info', data: [`Removing the task ${task}`] })
    delete provider[role].tasks[task]
    if (!idleProviders.includes(id)) idleProviders.push(id)
    provider.idleStorage += size
    if (status === 'done') {}
    if (status === 'fail') {}
    if (status === 'cancel') {}
    next_task(log)
  }
}
function doesQualify (plan, provider, role) {
  const form = provider.form
  if (
    isScheduleCompatible(plan, form, role) &&
    hasCapacity(provider, role) &&
    hasEnoughStorage(provider)
  ) return true
}
async function isScheduleCompatible (plan, form, role) {
  const blockNow = header.number
  const isAvialableNow = form.duration.from <= blockNow
  const until = form.duration.until
  var taskDuration
  if (role === 'attestor') taskDuration = 3
  if (role === 'encoder') taskDuration = 2 // duration in blocks
  if (role === 'hoster') taskDuration = plan.duration.until -  blockNow
  return (isAvialableNow && (until >= (blockNow + taskDuration) || isOpenEnded))
}
function hasCapacity (provider, role) {
  const tasks = provider[role].tasks
  return (Object.keys(tasks).length < provider[role].capacity)
}
function hasEnoughStorage (provider) {
  return (provider.idleStorage > size)
}
async function next_task (log) {
  const { scheduleAction } = await scheduler
  for (var start = new Date(); DB.queues.tasks.length && new Date() - start < 4000;) {
    const { fnName, id: task_id } = DB.queues.tasks[0]
    const task = getItemByID(task_id)
    log({ type: 'attestors task queue', data: { text: 'next task', task: JSON.stringify(task) } })
    if (fnName === 'amendment' && DB.status.idleAttestors.length && DB.status.idleEncoders.length >= 3 && DB.status.idleHosters.length >= 3) {
      const { contract: contract_id, providers: reuse } = task
      const { plan: plan_id } = getContractByID(contract_id)
      const type = 'NewAmendment'
      const providers = getProviders(getPlanByID(plan_id), reuse, task_id, log)
      if (providers) {
        DB.queues.tasks.shift()
        ;['attestor','encoder','hoster'].forEach(role => {
          const first = role[0].toUpperCase()
          const rest = role.substring(1)
          start_task({
            type,
            selectedProviders: providers[`${role}s`],
            idleProviders: DB[`idle${first + rest}s`],
            role,
            newTask: task_id,
            log
          })
        })
        const keys = Object.keys(providers)
        for (var i = 0, len = keys.length; i < len; i++) {
          providers[keys[i]] = providers[keys[i]].map(item => item.id)
        }
        log({ type: 'info', data: 
        { text: `Providers for amendment (${task_id})`,  providers} })
        task.providers = providers
        // schedule timeout action
        task.sid = scheduleAction({ from: log, data: { id: task_id }, delay: 2, type: 'amendment_timeout' })
        // emit event
        log({ type: 'info', data: { text: 'new event emitted', type, task_id } })
        emitEvent(type, [task_id], log)
      }
    }
    else if (fnName === 'NewStorageChallenge' && DB.status.idleAttestors.length) {
      // TODO schedule timeout
      const { hoster: hoster_id, contract: contract_id, id } = task
      const { plan: plan_id } = getContractByID(contract_id)
      const plan = getPlanByID(plan_id)
      const avoid = { [plan.sponsor]: true, [hoster_id]: true }
      const idleProviders = DB.status.idleAttestors
      const selectedProviders = select({ idleProviders, role: 'attestor', newTask: id, amount: 1, avoid, plan, log })
      const [provider] = selectedProviders
      if (selectedProviders.length) {
        DB.queues.tasks.shift()
        task.attestor = provider.id
        start_task({ type: fnName, selectedProviders, idleProviders, role: 'attestor', newTask: id, log })
        // emit event
        log({ type: 'info', data: [fnName, id] })
        emitEvent(fnName, [id], log)
      }
    }
    else if (fnName === 'NewPerformanceChallenge' && DB.status.idleAttestors.length) {
      // TODO schedule timeout
      const { hoster: hoster_id, contract: contract_id, id } = task
      const { plan: plan_id } = getContractByID(contract_id)
      const plan = getPlanByID(plan_id)
      const avoid = { [plan.sponsor]: true, [hoster_id]: true }
      const selectedProviders = select({ idleProviders: DB.status.idleAttestors, role: 'attestor', newTask: id, amount: 1, avoid, plan, log })
      if (selectedProviders.length) {
        DB.queues.tasks.shift()
        task.attestors = selectedProviders.map(provider => provider.id)
        start_task({ type: fnName, selectedProviders, idleProviders: DB.status.idleAttestors, role: 'attestor', newTask: id, log })
        // emit event
        log({ type: 'info', data: [fnName, id] })
        emitEvent(fnName, [id], log)
      }
    }
  }
}

function sig_verified (unique_el_signature, data, signingKey) {
  if (!datdot_crypto.verify_signature(unique_el_signature, data, signingKey)) return log({ type: 'info', data: [`Error: unique_el_signature could not be verified`] })
  return true
}
function cancelContracts (plan) {
  const contracts = plan.contracts
  for (var i = 0; i < contracts.length; i++) {
    const contractID = contracts[i]
    const contract = getContractByID(contractID)
    // tell hosters to stop hosting
    // TODO:
    // 1. figure out all active Hostings (=contracts) from plan (= active)
    // 2. figure out all WIP PerfChallenges for contracts from plan
    // 3. figure out all WIP StoreChallenges for contracts from plan
    // 4. figure out all WIP makeHosting (=amendments) from plan (= soon to become active)
    // 5. CHAIN ONLY: figure out all future scheduled makeHostings (=amendments) from plan

// for every hoster in last Amendment user.hoster.tasks[`NewAmendment${amendmentID}`] = false
// for every encoder in last  user.encoder.tasks[`NewAmendment${amendmentID}`] = false
// for every attestor in last  user.attestor.tasks[`NewAmendment${amendmentID}`] = false
// cancel scheduled challenges
// plan.contracts = [] => we need to rename to activeContracts
// add checks in extrinsics for when wip actions (make hostings, challenges) report back to chain =>
//     storageChallengeID
// if (DB.active.storageChallenges[id] ) const challenge = getStorageChallengeByID(storageChallengeID)

    const queue = priorityQueue(function compare (a, b) { return a.id < b.id ? -1 : 1 })
    // queue.size()
    // queue.add(item) // add item at correct position into queue
    // queue.take(index=0) // get front item and remove it from the queue
    // queue.peek(index=0) // check front item
    // queue.drop(function keep (x) { return item.contract !== id })
    const amendments = contract.amendments
    const active_amendment = getAmendmentByID(amendments[amendments.length-1])
    const hoster_ids = active_amendment.providers.hosters
    hoster_ids.forEach((hoster_id, i) => {
      remove_task({ id: hoster_id, role: 'hoster', task: contractID, idleProviders: DB.status.idleHosters, status: 'cancel', log })
      const { feed: feedID } = getContractByID(contractID)
      // TODO ACTION find new provider for the contract (makeAmendment(reuse))
      // emit event to notify hoster(s) to stop hosting
      emitEvent('DropHosting', [feedID, hoster_id], log)
    })
    // remove from tasks queue
    for (var j = 0; j < DB.queues.tasks; j++) {
      const { fnName, id } = DB.queues.tasks[j]
      if (fnName === 'amendment' && contractID === getAmendmentByID(id).contract) DB.queues.tasks.splice(j, 1)
    }
  }
}

function get_random_ids ({items, max}) {
  if (items.length < max) return items
  const selected = []
  while (selected.length < max) {
    const pos = Math.floor(Math.random() * items.length)
    if (!selected.includes(pos)) selected.push(pos)
  }
  return selected.map(pos => items[pos])
}

// TODO
// performance challenge 
  // group all challenges for same feed (all through same swarm) -> feed has many hosters (feed.contracts)
// storage challenge - group all challenges for same hoster (all through same beam connection) -> hoster hosts many feeds (user.hoster.tasks[amendmentID])

async function planValid ({ plan }) {
  const blockNow = header.number
  const { duration: { from, until } } = plan
  if ((until > from) && ( until > blockNow)) return true
}

async function _retry_amendment ({ failed, amendmentID, log }) {
  log({ type: 'info', data: { text: 'Retrying amendment' } })
  const amendment = getAmendmentByID(amendmentID)
  const { providers: { hosters, attestors, encoders }, contract: contract_id } = amendment
  const task = amendmentID
  for (var i = 0, len = failed.length; i < len; i++) {
    const id = failed[i]
    if (attestors.includes(id)) {
      attestors.splice(attestors.indexOf(id), 1)
      remove_task({ id, role: 'attestor', task, idleProviders: DB.status.idleAttestors, status: 'fail', log })
    }
    else if (hosters.includes(id)) {
      hosters.splice(hosters.indexOf(id), 1)
      remove_task({ id, role: 'hoster', task, idleProviders: DB.status.idleHosters, status: 'fail', log })
    }
    else if (encoders.includes(id)) {
      encoders.splice(encoders.indexOf(id), 1)
      remove_task({ id, role: 'encoder', task, idleProviders: DB.status.idleEncoders, status: 'fail', log })
    }
  }
  const reuse = { encoders, hosters, attestors } 
  emitEvent('DropTask', [amendmentID, failed], log)
  // TODO: add new amendment to contract only after it is taken from the queue
  
  // make new amendment
  log({ type: 'info', data: { text: 'Retry amendment', providers: reuse } })
  const newID = await init_amendment(contract_id, reuse, log)
  // TODO ACTION find new provider for the contract (makeAmendment(reuse))
  DB.queues.tasks.push({ fnName: 'amendment', id: newID }) // TODO sort tasks based on priority (RATIO!)
  next_task(log)
}

function isValidHoster ({ hosters, failedHosters, hosterID }) {
  // is hoster listed in the amendment for hosting and is hoster not listed as failed (by the attestor)
  if (!hosters.includes(hosterID) || failedHosters.includes(hosterID)) return log({ type: 'info', data: [`Error: this user can not call this function`] })
  return true
}

function emitEvent (method, data, log) {
  const message = [{ event: { data, method } }]
  eventpool.push([log, message])
}

function get_datasets (plan) {
  const dataset_ids = plan.program.map(item => item.dataset).flat()
  return dataset_ids.map(id => getDatasetByID(id))
}