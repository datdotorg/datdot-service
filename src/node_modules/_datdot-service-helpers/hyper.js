const hyperswarm = require('hyperswarm')
const hypercore = require('hypercore')
const RAM = require('random-access-memory')
const datdot_crypto = require('datdot-crypto')
const mux_proto = require('_datdot-service-helpers/mux-proto')
const b4a = require('b4a')
const c = require('compact-encoding')
const try_refresh_discovery = require('_datdot-service-helpers/try-refresh-discovery')
const safetyCatch = require('safety-catch')
const {
	done_task_cleanup,
	remove_from_roles,
	get_tasks_for_roles,
	close_feeds,
	remove_from_tasks,
	get_connections,
	remove_from_feeds,
	decrease_socket_count,
	remove_from_targets,
	get_socket_count,
	remove_from_sockets,
	close_streams_and_channels,
	get_peer_tasks,
	remove_from_target_tasks,
	remove_from_task_connections,
	remove_from_registry,
	get_tasks
} = require('_datdot-service-helpers/done-task-cleanup')


module.exports = hyper

function hyper (account, bootstrap) {
	const api = {
		new_task: (opts) => _new_task(account, opts),
		connect: (opts) => _connect(account, bootstrap, opts),
	}
	return api
}
/* --------------------------------------------------------------------------------------------

	NEW TASK

-----------------------------------------------------------------------------------------------*/
async function _new_task(account, { newfeed = true, feedkey, topic, log }) { // newfeed false for receivers of feedkey (attestor, hoster)
	// log({ type: 'hyper', data: { text: 'starting new task (ex load feed' }})
	var feed
	var stringkey
	var stringtopic
	if (!account.state) account.state = { sockets: {}, feeds: {}, targets: {}, tasks: {} }
	const feeds = account.state.feeds
	
	// 0. If feedkey and/or topic, get stringkey and stringtopic
	if (topic) { 
		topic = Buffer.isBuffer(topic) ? topic : b4a.from(topic, 'hex')
		stringtopic = topic.toString('hex') 
	}
	if (feedkey) { // when feed key with or without topic
		feedkey = Buffer.isBuffer(feedkey) ? feedkey : b4a.from(feedkey, 'hex')
		stringkey = feedkey.toString('hex')
		if (!topic) {
			topic = datdot_crypto.get_discoverykey(feedkey)
			stringtopic = topic.toString('hex')
		}
	} 
	
	// 1. Get or make feed
	if (stringtopic && stringkey && feeds[stringtopic]) { // get existing feed
		log({ type: 'hyper', data: { text: 'Existing feed', stringkey, stringtopic }})
		feed = feeds[stringtopic][stringkey].feed 
	} else { // make new feed
		if (newfeed) {  // attestor and hoster have to wait to receive feedkey first, so no new feed for them
			if (feedkey) {
				// log({ type: 'hyper', data: { text: 'New feed', stringkey: feedkey.toString('hex') }})
				feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
				add_to_feeds({ feeds, stringtopic, stringkey, feed })
				await feed.ready().catch(safetyCatch)
			} else {
				feed = new hypercore(RAM, { valueEncoding: 'binary', sparse: true })
				// log({ type: 'hyper', data: { text: 'New feed', stringkey: 'none' }})
				await feed.ready().catch(safetyCatch)
				feedkey = feed.key
				stringkey = feedkey.toString('hex')
				if (!topic) topic = datdot_crypto.get_discoverykey(feedkey)
				if (!stringtopic) stringtopic = topic.toString('hex')
				add_to_feeds({ feeds, stringtopic, stringkey, feed })
			}
			log({ type: 'hyper', data: { text: 'New feed', stringkey, stringtopic }})
		}
	}

	return { feed }
}
/* --------------------------------------------------------------------------------------------

	CONNECT

-----------------------------------------------------------------------------------------------*/
async function _connect ( account, bootstrap, { swarm_opts, targets: Targets, log }) {
	Targets = Object.assign({ targetList: [], ontarget: noop, done: noop, msg: {} }, Targets)
	const { targetList, ontarget, msg, feed, done } = Targets
	var { role, topic, mode } = swarm_opts
	const { noisePublicKey, noisePrivateKey, state } = account
	var { swarm, tasks, targets, sockets } = state
	var stringtopic
	
	// log({ type: 'connect', data: { text: 'load-store connect', msg }})

	if (!topic) throw new Error('Error: Can not connect without topic')
	topic = Buffer.isBuffer(topic) ? topic : b4a.from(topic, 'hex')
	stringtopic = topic.toString('hex') 

	// 2. Make swarm
	if (!swarm) {
		swarm = new hyperswarm({ 
			bootstrap, 
			keyPair: { publicKey: noisePublicKey, secretKey: noisePrivateKey }, 
			maxParallel: Infinity, 
			maxPeers: Infinity 
		})
		account.state.swarm = swarm
		log({ type: 'store connect', data: { text: 'new swarm', mode }})
		swarm.on('connection', onconnection(account, log))
	}

	// 3. Store tasks (for topic)
	add_to_tasks({ tasks, stringtopic, role, log })

	// 3. Join peer through existing channel or join the swarm on topic
	if (!targetList.length) { // Join topic (if no targetList && no discovery yet)
		if (!swarm.status(topic)) {
			log({ type: 'store connect', data: { text: 'Join swarm', mode, stringtopic }})
			await swarm.join(topic, mode).flushed()
		} else {
			log({ type: 'store connect', data: { text: 'try refresh discovery', mode, stringtopic }})
			mode =  await try_refresh_discovery({ swarm, topic, tasks: tasks[stringtopic].roles, log })
		}
	} else { // connect only to the targets on the list
		// topic created with derive-topic is not a valid topic
		// but we connect to targets on targetList directly so the topic
		for (const remotestringkey of targetList) {
			add_to_targets({ targets, remotestringkey, stringtopic, ontarget, feed, msg, done, log })					
			if (sockets[remotestringkey]) {
				log({ type: 'store connect', data: { text: 'Target - existing socket', connections_count: sockets[remotestringkey].count }})
				exchange_feedkey({ account, remotestringkey, log }) // feed will be returned with ontarget callback
			} else {				
				// Join peer (if no socket connection && no discovery yet)
				log({ type: 'store connect', data: { text: 'Target - joinPeer', remotestringkey, stringtopic, mode }})
				await swarm.joinPeer(b4a.from(remotestringkey, 'hex'))
				await swarm.listen() // explicitly start listening for incoming connections
			}
		}
	}
}
/* --------------------------------------------------------------------------------------------

	ONCONNECTION

-----------------------------------------------------------------------------------------------*/
function onconnection (account, conn_log) {
	return async (connection, peerInfo) => {
		try {
			const { state } = account
			const { swarm, targets, tasks, sockets } = state
			const remotekey = peerInfo.publicKey
			const remotestringkey = remotekey.toString('hex')	
			const conn_log = account.log.sub(`<-onconnection: me: ${account.noisePublicKey.toString('hex').substring(0,5)}, peer: ${remotestringkey.substring(0,5)} `)
			conn_log({ type: 'onconnection', data: { text: 'onconnection callback', remotestringkey } })
			
			await load_replicationStream({ account, connection, remotestringkey, log: conn_log })
			// this is the peer we need to exchange feedkeys with
			if (targets[remotestringkey]) return exchange_feedkey({ account, remotestringkey, log: conn_log }) 

			// peer is a client
			const peer_topics = peerInfo.topics
			if (!peer_topics.length) return 
			for (const topic of peer_topics) {
				const stringtopic = topic.toString('hex') // only shows topics derived from a feed.discoveryKey
				if (!tasks[stringtopic || tasks[stringtopic].connections[remotestringkey]]) continue
				handle_matching_topic({ stringtopic, remotestringkey, state, log: conn_log })
			}
		} catch (err) {
			conn_log({ type: 'Error', data: { text: 'Error: in onconnection', err }})
		}
	}
}		

async function load_replicationStream ({ account, connection, remotestringkey, log }) {
	log({ type: 'onconnection', data: { text: 'loading replication stream and channel', remotestringkey } })
	try {
		const { tasks, sockets, targets } = account.state
		var replicationStream
		if (sockets[remotestringkey]) {
			log({ type: 'onconnection', data: { text: 'existing connection', remotestringkey, isInitiator: connection.isInitiator } })
			replicationStream = sockets[remotestringkey].replicationStream
		} else {
			log({ type: 'onconnection', data: { text: 'new connection', remotestringkey, isInitiator: connection.isInitiator } })
			replicationStream = hypercore.createProtocolStream(connection, { ondiscoverykey })
			mux = hypercore.getProtocolMuxer(replicationStream)
			add_to_sockets({ sockets, remotestringkey, connection, replicationStream, mux })			
			add_stream_listeners({ state: account.state, remotestringkey, log })
		}
		return { replicationStream }

		// peer is a server
		function ondiscoverykey (discoverykey) { // client hasn't replicated the hypercores so they are asking for the 'discovery-key' event
			const stringtopic = discoverykey.toString('hex') // only shows topics derived from a feedn.discoveryKey
			const connections = tasks[stringtopic]?.connections
			if (targets[remotestringkey] || !tasks[stringtopic] || connections[remotestringkey]) return
			handle_matching_topic({ stringtopic, remotestringkey, state: account.state, log })
		}
	} catch (err) {
		log({ type: 'Error', data: { text: 'Error: in loading replication stream and channel', err }})
	}
}

function handle_matching_topic ({ stringtopic, remotestringkey, state, log }) {
	const { sockets, tasks } = state
	const replicationStream = sockets[remotestringkey].replicationStream
	add_to_connections({ connections: tasks[stringtopic].connections, remotestringkey })
	increase_socket_count({ sockets, remotestringkey, log })
	log({ type: 'onconnection', data: { text: 'matching topic', remotestringkey, stringtopic } })
	replicate_feeds({ state, stringtopic, replicationStream, log })
}

function replicate_feeds ({ state, stringtopic, replicationStream, log }) {
	try {
		const { swarm, feeds } = state
		const feedkeys = Object.keys(feeds[stringtopic])
		const status = swarm.status(b4a.from(stringtopic, 'hex'))
		if (!status) return		
		for (const key of feedkeys) {
			const feed = feeds[stringtopic][key].feed
			if (!feed.opened || feed.closing) {
				log({ type: 'replicate', data: { text: 'feed closing or closed', open: feed.opened, closing: feed.closing, stringtopic, feedkey: feed.key.toString('hex') } })
				continue
			}
			log({ type: 'replicate', data: { text: 'replicate feed', stringtopic, feedkey: feed.key.toString('hex') } })
			feed.replicate(replicationStream)
		}
	} catch (err) {
		log({ type: 'Error', data: { text: 'Error: replicating feeds in the general swarm', err }})
	}
}

async function exchange_feedkey ({ account, remotestringkey, log }) { //get feedkey from or send to a target peer (on each custom topic)
	const { state } = account
	const { targets, sockets, tasks } = state
	const target_tasks = Object.keys(targets[remotestringkey].tasks)
	log({ type: 'onconnection', data: { text: `exchange feedkey`, remotestringkey, target_tasks: target_tasks.length } })				
	increase_socket_count({ sockets, remotestringkey, log })
	
	var channel
	channel = await new_channel({ account, remotestringkey, log }).catch(err => {
		log({ type: 'exchange-feedkey', data: { text: 'Error: in new channel', remotestringkey, err }})
		if (err.type === 'Error: in new channel') {
			channel = err.channel
		} else return
	})
	if (!channel) return log({ type: 'exchange-feedkey', data: { text: 'Error: channel', remotestringkey }})
	log({ type: 'exchange-feedkey', data: { text: 'new channel returned', remotestringkey, opened: channel.opened }})

	// load registry
	const string_msg = channel.messages[0] // get string message type for sending strings through the mux channel with that peer (channel.addMessage(...))
	var registry = string_msg.registry
	
	// we need to loop over all the target tasks to find tasks for this peer
	for (const stringtopic of target_tasks) {
		try {
			const { msg, log } = targets[remotestringkey].tasks[stringtopic]
			log({ type: 'exchange feedkey', data: { text: `current peer ${remotestringkey} for topic ${stringtopic}`, target_tasks  } })
			const connections = tasks[stringtopic].connections
			if (connections[remotestringkey]) continue
			add_to_connections({ connections, remotestringkey })

			// check if any messagges are waiting in the queue
			const entry = registry.get(stringtopic)				
			log({ type: 'exchange feedkey', data: { text: `registry entry`, stringtopic, remotestringkey, entry: entry ? 'yes' : 'no'   } })
			if (!entry) {
				string_msg.registry.set(stringtopic, { onmessage })
			} else {
				const { msg_queue } = entry
				if (msg_queue) msg_queue.forEach(message => onmessage({ message, remotestringkey, string_msg, state }))
				entry.msg_queue = void 0
				entry.onmessage = onmessage
			}
			if (msg.send) { // see if we need to send or to receive a message
				const { feed } = targets[remotestringkey].tasks[stringtopic]
				log({ type: 'protomux', data: { text: `send feedkey` } })
				string_msg.send(JSON.stringify({ type: 'feedkey', feedkey: feed.key.toString('hex'), stringtopic }))
			} 
		} catch (err) {
			log({ type: 'error', data: { text: 'Error: exchange feedkey', err, remotestringkey, stringtopic  } })
		}
	}
}

function new_channel ({ account, remotestringkey, log }) {
	log({ type: 'protomux', data: { text: `new channel`, remotestringkey } })
	return new Promise(async (resolve, reject) => {
		try {
			const { state } = account
			const { sockets } = state
			var { mux, channel } = sockets[remotestringkey]
			if (channel) resolve(channel)
			
			// make a protocol
			const opts = { protocol: 'datdot/alpha' }
			mux_proto.make_protocol({ mux, opts, cb, log })
			
			async function cb () {
				log({ type: 'protomux', data: { text: 'new channel cb', remotestringkey }}) 
				if (mux.opened(opts)) {
					channel = sockets[remotestringkey].channel
					log({ type: 'protomux', data: { text: 'mux already opened', remotestringkey, channel: channel?'yes':'no' }}) 
					// if (channel) reject({ type: 'channel already exists', channel })
					return
				}
				channel = mux_proto.create_and_open_channel({ mux, opts: {...opts, onopen, onclose }, log })
				if (!channel) return reject()

				// add message types for different encodings (i.e. string...) + intercept onmessage with a dispacher
				const string_msg = channel.addMessage({ encoding: c.string, onmessage: dispacher })
				sockets[remotestringkey].channel = channel				
				
				// load registry to store onmessage callbacks and undelivered messages (msg_queue) for each stringtopic
				var registry = string_msg.registry
				if (!registry) registry = string_msg.registry = new Map()

				// dispacher stores the message in the queue until we can process it
				// example: chain emits the event bob receives it and send the message, but alice hasn't received the event yet
				function dispacher (message) {
					const { stringtopic } = JSON.parse(message)
					const entry = registry.get(stringtopic)
					log({ type: 'dispacher', data: { text: 'registry entry', entry: entry ? 'yes' : 'no' }}) 
					if (!entry) {
						return registry.set(stringtopic, { msg_queue: [message] })		
					} 
					const { onmessage, msg_queue } = entry
					onmessage ? onmessage({ message, remotestringkey, string_msg, state }) : msg_queue.push(message)
				}
			}	

			function onopen () { 
				log({ type: 'protomux', data: { text: 'onopen: either side opened channel' }}) 
				return resolve(channel)
			}
			async function onclose (isRemote, channel) { 
				log({ type: 'protomux', data: { text: 'onclose: either side closed channel', isRemote, stream_opened: await mux.stream.opened }})
			}

		} catch (err) {
			log({ type: 'protomux', data: { text: `Error: new channel`, remotestringkey } })
			reject(err)
		}
	})
}

async function onmessage ({ message, remotestringkey, string_msg, state }) {
	const { type, feedkey, stringtopic, proof_of_contact } = JSON.parse(message)
	const { feeds, targets, sockets } = state
	const { replicationStream } = sockets[remotestringkey]
	const { ontarget, done, log } = targets[remotestringkey].tasks[stringtopic]
	log({ type: 'onmessage', data: { text: 'new message received', type } })

	var feed
	if (type === 'feedkey') {	// make feed
		log({ type: 'onmessage protomux', data: { text: 'received feedkey', feedkey: feedkey.toString('hex') }})
		feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
		await feed.ready().catch(safetyCatch)
		const stringkey = feedkey.toString('hex')
		add_to_feeds({ feeds, stringtopic, stringkey, feed })
		string_msg.send(JSON.stringify({ type: 'ack-feedkey', stringkey, stringtopic }))
		replicate_to_target({ ontarget, feed, replicationStream, remotestringkey, stringtopic, log })
	} 
	else if (type === 'ack-feedkey') {
		feed = targets[remotestringkey].tasks[stringtopic].feed
		log({ type: 'onmessage protomux', data: { text: 'received ack', stringkey: feed.key.toString('hex') }})
		replicate_to_target({ ontarget, feed, replicationStream, remotestringkey, stringtopic, log })
	}
	else if (type === 'proof-of-contact') {
	  log({ type: 'proof of contact', data: { proof_of_contact } })
		string_msg.send(JSON.stringify({ type: 'ack-proof-of-contact', stringtopic }))
		done(proof_of_contact)
	}
	else if (type === 'ack-proof-of-contact') {
		log({ type: 'ack-proof-of-contact', data: { stringtopic } })
		done()
	}
}		

function replicate_to_target ({ ontarget, feed, replicationStream, remotestringkey, stringtopic, log }) {
	if (!feed.opened || feed.closing) return
	feed.replicate(replicationStream)
	log({ type: 'replicate', data: { text: 'replicate to target', stringtopic  }})
	ontarget({ feed, remotestringkey })
}
/*-----------------------------------------------------------------------------------------------------
		
	HELPERS
		
------------------------------------------------------------------------------------------------------*/
function add_to_tasks ({ tasks, stringtopic, role, log }) {
	if (!tasks[stringtopic]) {
		tasks[stringtopic] = { roles: { [`${role}`]: 1 }, connections: {} } 
		log({ type: 'hyper', data: { text: 'New topic', role, stringtopic }})
	} else {
		tasks[stringtopic].roles[`${role}`] ? tasks[stringtopic].roles[`${role}`]++ : tasks[stringtopic].roles[`${role}`] = 1
		log({ type: 'hyper', data: { text: 'Existing topic', role, stringtopic, tasks: tasks[stringtopic] }})
	}
}

function add_to_targets ({ targets, remotestringkey, stringtopic, ontarget, feed, msg, done, log }) {
	if (!targets[remotestringkey]) targets[remotestringkey] = { tasks: { [stringtopic]: { ontarget, feed, msg, done, log } } }
	else targets[remotestringkey].tasks[stringtopic] = { ontarget, feed, msg, done, log }
}
		
function add_to_sockets ({ sockets, remotestringkey, connection, replicationStream, mux }) {
	sockets[remotestringkey] = { socket: connection, replicationStream, mux, count: 0 }
}

function increase_socket_count ({ sockets, remotestringkey, log}) {
	sockets[remotestringkey].count++
	log({ type: 'socket', data: { text: 'Increase count', remotestringkey, count: sockets[remotestringkey].count   }})
}

function add_to_connections ({ connections, remotestringkey }) {
	connections[remotestringkey] = true
}

function add_to_feeds ({ feeds, stringtopic, stringkey, feed }) {
	if (!feeds[stringtopic]) feeds[stringtopic] = {}
	if (!feed) return
	feeds[stringtopic] = { [stringkey]: { feed } }
}

function add_stream_listeners ({ state, remotestringkey, log }) {
	const { sockets } = state
	const { replicationStream } = sockets[remotestringkey]

	replicationStream.on('error', (err) => { 
		// log({ type: 'replicationStream on', data: { text: `on error: replicationStream error`, err, code: err.code, stack: err.stack /*snapshot: get_snapshot(account, remotestringkey)*/ } })
	})
	replicationStream.on('close', () => { 
		log({ type: 'replicationStream on', data: { text: `on close: replicationStream closed` } }) 
		if (sockets[remotestringkey]) {
			handle_onclose({ state, remotestringkey, log })
		}
	})
	replicationStream.on('end', () => { 
		log({ type: 'replicationStream on', data: { text: `on end: replicationStream ended` } })
	})
	replicationStream.on('timeout', (err) => { 
		log({ type: 'replicationStream on', data: { text: `ontimeout: replicationStream timed out` } }) 
	})
	replicationStream.on('data', (data) => { 
		// log({ type: 'replicationStream on', data: { text: `on data: replicationStream`, data, stack: err.stack } }) 
	})
}

function handle_onclose ({ state, remotestringkey, log }) {
	log({ type: 'on close', data: { text: `handling on close event` } }) 
	const { swarm, sockets, targets, tasks, feeds } = state
	const all_topics = get_tasks({ tasks, log })

	for (const stringtopic of all_topics) {
		const task = tasks[stringtopic]

		if (task.connections[remotestringkey]) {
			decrease_socket_count({ sockets, remotestringkey, log })
			if (targets[remotestringkey]) {
				remove_from_target_tasks({ targets, stringtopic, remotestringkey, log }) // we have always only one task per stringtopic
				const peer_tasks = get_peer_tasks({ targets, remotestringkey, log })
				if (!peer_tasks.length) {
					remove_from_targets({ targets, remotestringkey, log })
					remove_from_registry({ sockets, stringtopic, remotestringkey, log })
				}
			}
			const connections_for_socket = get_socket_count({ sockets, remotestringkey, log })
			if (!connections_for_socket && !targets[remotestringkey]) {
				close_streams_and_channels({ sockets, remotestringkey, log })
				remove_from_task_connections({ tasks, stringtopic, remotestringkey, log })
				remove_from_sockets({ sockets, remotestringkey, log })
			}
			const topic_tasks = get_tasks_for_roles({ tasks, stringtopic, log })
			if (!topic_tasks) { 
				if (!task.roles['author']) {
					swarm.leave(topic) 
					close_feeds({ feeds, stringtopic, log })
				}
				remove_from_tasks({ tasks, stringtopic, log })
			}
		}

	}

}

 

function noop () {}

/* --------------------------------------------------------------------------------------------

	state

-----------------------------------------------------------------------------------------------*/

/* 
account = {
	storage: {
			feedkey: { feed, db, discovery, unintercept }
	},
	state:  {
			swarm,
			sockets: {
					[remotestringkey]: { 
							count: 1 // connection count
							socket, 
							replicationStream,
							mux,
							channel: {
								messages: {
									// different types, our only type for now is string_msg (channel.messages[0])
									registry: { msg_queue: [message], onmessage }
									onmessage: dispacher
								}
							},
					}
			},
			tasks: {
				[stringtopic]: {
					connections: {
						[remotestringkey]: true
					},
					roles: {
						author: 0, // { server: true }
						sponsor: 0, // { client: true } 
						encoder2author: 1, // { client: true }
						encoder2attestor: 0, // { server: true }
						attestor2encoder: 0, // { client: true }
						attestor2hoster: 0, // { server: true }
						hoster2author: 0, // { server: true, client: true }
						hoster2attestor: 0, // { client: true }
						hoster2peers: 0, // { server: true }
						perf_attestor: 0 
					}
				}
			}
			feeds: {
				[stringtopic]: {
					[stringkey]: { feed }
				}
			}
			targets: {  
				[remotestringkey]: {
					tasks: {
						[stringtopic1]: { feed, msg: { receive, send }, ontarget, done, log },
						[stringtopic2]: { feed, msg: { receive, send }, ontarget, done, log }
					}
				}
			},
			// targets are created only when we have a msg (send or receive) and a targetList and we need to exchange keys first and then replicate
	},
} 

*/