const try_refresh_discovery = require('_datdot-service-helpers/try-refresh-discovery')

module.exports = done_task_cleanup

async function done_task_cleanup ({ role, topic, cache, log }) {
	// NOTE: the initiator calls this
	return new Promise(async (resolve, reject) => {
		const { swarm, sockets, feeds, targets, tasks } = cache
		const stringtopic = topic.toString('hex')
		log({ type: 'cleanup', data: { text: 'cleanup', role, topic: topic.toString('hex') }})
		
		const { 
			author, // { server: true }
			sponsor, // { client: true } 
			encoder2author, // { client: true }
			encoder2attestor, // { server: true }
			attestor2encoder, // { client: true }
			attestor2hoster, // { server: true }
			hoster2author, // { server: true, client: true }
			hoster2attestor, // { client: true }
			hoster2peers, // { server: true }
			perf_attestor 
		} = tasks[stringtopic] 
		
		try {
			if (role === 'hoster2author') {
				tasks[stringtopic]['hoster2peers'] ? tasks[stringtopic]['hoster2peers']++ : tasks[stringtopic]['hoster2peers'] = 1
			}
			log({ type: 'cleanup', data: { text: 'before cleanup', stringtopic, role, task_count: tasks[stringtopic].roles[`${role}`] } })
			tasks[stringtopic].roles[`${role}`]--
			
			// get all active connections (remotestringkeys) for this topic
			const connections = Object.keys(tasks[stringtopic].connections)
			
			// all task for any of the roles, delete tasks[stringtopic]
			var tasks_for_topic = 0
			Object.keys(tasks[stringtopic].roles).map(role => {
				tasks_for_topic += tasks[stringtopic].roles[role]
				return [ role, tasks[stringtopic].roles[role]] 
			})
			
			// check for each remotestringkey if there are jobs (count) left for that key
			const conn_len = connections.length
			for (var i = 0; i < conn_len; i++) {
				const remotestringkey = connections[i]
				log({ type: 'cleanup', data: { 
					role,
					remotestringkey, 
					sockets: Object.keys(sockets),
					stringtopic,
					connections_for_topic: Object.keys(tasks[stringtopic].connections), 
					tasks_for_topic
				}})

				// delete stuff related to target peers
				if (targets[remotestringkey]) {				
					delete targets[remotestringkey].topics[stringtopic]
					const peer_topics_len = Object.keys(targets[remotestringkey].topics).length
					if (peer_topics_len === 0) delete targets[remotestringkey]
					const string_msg = sockets[remotestringkey].channel.messages[0]
					string_msg.registry.delete(stringtopic)
				}

				const { socket, count, replicationStream, channel, mux } = sockets[remotestringkey]
				sockets[remotestringkey].count--
				if (sockets[remotestringkey].count === 0 && tasks_for_topic === 0) {
					log({ type: 'cleanup', data: { text: 'socket count 0', remotestringkey }})
					// if job count for this remotestringkey is 0, close/end stuff
					socket.destroy()
					channel.close()
					replicationStream.destroy()
					mux.destroy()
					// and delete the connection and the socket from cache 
					delete tasks[stringtopic].connections[remotestringkey]
					delete cache.sockets[remotestringkey]
				}
			}


			// if no tasks, leave topic and close feeds
			if (tasks_for_topic === 0) { 
				log({ type: 'cleanup', data: { text: 'leaving topic, no active tasks', stringtopic } })
				swarm.leave(topic) // stop getting new connections on topic. leave will not close any existing connections.
				
				const feedkeys = Object.keys(feeds[stringtopic])
				feedkeys.forEach(async key => {
					const {feed} = feeds[stringtopic][key]
					await feed.core.close()
				})

				delete tasks[stringtopic]
				
				return resolve()
			}

			const mode = await try_refresh_discovery({ swarm, topic, tasks: tasks[stringtopic].roles, log })
			resolve()
		} catch(err) {
			log({ type: 'cleanup', data: { text: 'Error: in done task cleanup', stringtopic, err }})
			reject()
		}  
	})
}