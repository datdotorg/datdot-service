const update_swarm_discovery = require('./update-swarm-discovery')

module.exports = done_task_cleanup

async function done_task_cleanup ({ role, topic, cache, log }) {
	// NOTE: the initiator calls this
	return new Promise(async (resolve, reject) => {
		return resolve()
		const { swarm, topics, sockets, feeds, peers, tasks } = cache
		const stringtopic = topic.toString('hex')
		log({ type: 'task', data: { text: 'Removing task from cache', role, topic }})
		
		const { 
			author, // { server: true }
			sponsor, // { client: true } 
			encoder2author, // { client: true }
			encoder2attestor, // { server: true }
			attestor2encoder, // { client: true }
			attestor2hoster, // { server: true }
			hoster2author, // { server: true, client: true }
			hoster2attestor, // { client: true }
			hoster2peers, // { server: true }
			perf_attestor 
		} = tasks[stringtopic] 
		
		
		try {
			if (role === 'hoster2author') {
				tasks[stringtopic]['hoster2peers'] ? tasks[stringtopic]['hoster2peers']++ : tasks[stringtopic]['hoster2peers'] = 1
			}
			tasks[stringtopic][`${role}`]--

			// get all active connections (remotestringkeys) for this topic
			const connections = Object.keys(topics[stringtopic].connections)
			const all_conn = []
			Object.keys(topics).forEach(stringtopic => all_conn.push(...Object.keys(topics[stringtopic].connections)))
			// get all remotekeys peer is connected to
			const remotekeys = Object.keys(sockets)

			// check for each remotestringkey if there are jobs (count) left for that key
			connections.forEach(async remotestringkey => {
				const { socket, count, replicationStream, channel, mux } = sockets[remotestringkey]
				sockets[remotestringkey].count--
				if (sockets[remotestringkey].count === 0) {
					log({ type: 'task', data: { text: 'No more count for this socket', remotestringkey, count: sockets[remotestringkey].count }})
					// if job count for this remotestringkey is 0, close/end stuff
					socket ? socket.end() : log({ type: 'task', data: { text: 'Error: no socket' }})
					channel ? channel.close() : log({ type: 'task', data: { text: 'No channel to close' }})
					replicationStream ? replicationStream.end() : log({ type: 'task', data: { text: 'Error: no replicationStream' }})
					// and delete the connection and the socket from cache 
					delete topics[stringtopic].connections[remotestringkey]
					delete cache.sockets[remotestringkey]
				}
			})

			var all_tasks_count = 0
			const all_tasks = Object.keys(tasks[stringtopic]).map(role => {
				all_tasks_count += tasks[stringtopic][role]
				return [ role, tasks[stringtopic][role]] 
			})
			log({ type: 'task', data: { 
				text: 'Done task cleanup', 
				connections_for_topic: Object.keys(topics[stringtopic].connections), 
				stringtopic, 
				all_sockets: Object.keys(sockets), 
				all_tasks_count_for_topic: all_tasks_count, 
				all_tasks: JSON.stringify(all_tasks),
				role  
			}})

			// if no tasks, leave topic and close feeds
			if (!all_tasks_count) { 
				log({ type: 'replicate feeds', data: { text: 'leaving topic, no active tasks', stringtopic } })
				swarm.leave(topic) // stop getting new connections on topic. leave will not close any existing connections.
				
				const feedkeys = Object.keys(feeds[stringtopic])
				feedkeys.forEach(async key => {
					const {feed} = feeds[stringtopic][key]
					await feed.core.close()
				})

				delete tasks[stringtopic]
				delete topics[stringtopic]
				
				return resolve()
			}

			const mode = await update_swarm_discovery({ swarm, topic, tasks: tasks[stringtopic], log })
			resolve()
		} catch(err) {
			log({ type: 'task', data: { text: 'Error: in done task cleanup', stringtopic, err }})
			reject()
		}  
	})
}