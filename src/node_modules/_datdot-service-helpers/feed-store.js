const hyperswarm = require('hyperswarm')
const hypercore = require('hypercore')
const NoiseSecretStream = require('@hyperswarm/secret-stream')
const HypercoreProtocol = require('hypercore-protocol')
const RAM = require('random-access-memory')
const register_extension = require('_datdot-service-helpers/register-extension')
const ready = require('_datdot-service-helpers/hypercore-ready')
const datdot_crypto = require('../datdot-crypto')
const FeedStorage = require('_datdot-service-helpers/feed-storage.js')
const sub = require('subleveldown')
const b4a = require('b4a')


module.exports = feed_store

function feed_store (account, bootstrap) {
	const api = {
		load_feed: (opts) => _load_feed(account, bootstrap, opts),
		no_tasks: (opts) => _no_tasks(account, opts)
	}
	return api
}

function noop () {}

async function _load_feed(account, bootstrap, { extension = {}, swarm_opts, peers, feedkey, log }) {
	const { noisePublicKey, noisePrivateKey } = account
	console.log({bootstrap, noisePublicKey })
	var { topic, mode } =  swarm_opts
	mode = { client: true, server: true } // TODO: should every peer really be both, so we can reuse the swarm
	const { ext_cbs, name } = extension
	peers = Object.assign({ peerList: [], onpeer: noop, msg: {} }, peers)
	const { peerList, onpeer, msg } = peers
	const { send, receive } = msg // send or receive key from peerList peers

	log({ type: 'feed-store', data: { text: 'loading feed', peerList: peerList.length, msg, extension, swarm_opts, peers, feedkey }})
	
	var feed
	var stringkey
	var stringtopic
	var swarm
	var discovery
	
	if (!account.cache) account.cache = { sockets: {}, topics: {}, peers: {}, tasks: {} }
	const topics = account.cache.topics

	// 0. If feedkey and/or topic, get stringkey and stringtopic
	if (topic) { // when msg.receive or msg.send (no feedkey, only topic)
		topic = Buffer.isBuffer(topic) ? topic : b4a.from(topic, 'hex')
		stringtopic = topic.toString('hex') 
	}
	if (feedkey) { // when feed key with or without topic
		stringkey = feedkey.toString('hex')
		if (!topic) {
			topic = datdot_crypto.get_discoverykey(feedkey)
			stringtopic = topic.toString('hex')
		}
	} 
	
	// 1. Get or make feed
	if (stringtopic && topics[stringtopic]?.feeds[stringkey]) { // get existing feed
		feed = topics[stringtopic].feeds[stringkey].feed 
		log({ type: 'feed-store', data: { text: 'Existing feed', stringkey, stringtopic }})
	} else { // make new feed
		if (!receive) { 
			if (feedkey) {
				log({ type: 'feed-store', data: { text: 'Making new feed with feedkey', stringkey, stringtopic }})
				feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
			} else {
				feed = new hypercore(RAM, { valueEncoding: 'binary', sparse: true })
				log({ type: 'feed-store', data: { text: 'Making new feed without feedkey', stringkey, stringtopic }})
				await feed.ready()
				feedkey = feed.key
				stringkey = feedkey.toString('hex')
				if (!topic) topic = datdot_crypto.get_discoverykey(feedkey)
				if (!stringtopic) stringtopic = topic.toString('hex')
			}
			log({ type: 'feed-store', data: { text: 'New feed', stringkey, stringtopic }})
		}
		// 2. Store topic and feed (for new feed)
		if (!topics[stringtopic]) topics[stringtopic] = { feeds: {}, sockets: {} } // add topic to the cache
		if (feed) topics[stringtopic].feeds[stringkey] = { feed }
		log({ type: 'feed-store', data: { text: 'New topic stored in cache', stringtopic }})
	}
	
	// 3. Store peers (if peerList)
	peerList.forEach(remotestringkey => {
		const peers = account.cache.peers
		if (!peers[remotestringkey]) peers[remotestringkey] = { [stringtopic]: { onpeer, feed, msg } }
		else peers[remotestringkey][stringtopic] = { onpeer, feed, msg }
		const list = Object.keys(account.cache.peers[remotestringkey])
		// const list = Object.keys(account.cache.peers[remotestringkey]).map(topic => account.cache.peers[remotestringkey][topic])
		console.log({ logging_name: log.path, list, remotestringkey, stringtopic, topics })
	})

	// 4. Add task
	const tasks = account.cache.tasks
	if (!tasks[stringtopic]) tasks[stringtopic] = 1
	else tasks[stringtopic]++

	// 5. Make swarm
	if (!account.cache.swarm) {
		swarm = new hyperswarm({ bootstrap, keyPair: { publicKey: noisePublicKey, secretKey: noisePrivateKey } })
		account.cache.swarm = swarm
		log({ type: 'feed-store', data: { text: 'new swarm', mode }})
		swarm.on('connection', onconnection(account, log))
	} else swarm = account.cache.swarm
	
	// 6. Join topic (if no discovery yet)
	var discovery = topics[stringtopic].discovery
	if (!discovery) {
		log({ type: 'feed-store', data: { text: 'making new discovery' }})
		await swarm.join(topic, mode).flushed()
		topics[stringtopic].discovery = swarm.status(topic)
		log({ type: 'feed-store', data: { text: 'joined the swarm', mode, stringtopic }})
	}

	if (!receive) {
		log({ type: 'feed-store', data: { text: 'returning feed', stringkey }})
		return { feed }
	}
}

async function _no_tasks (account, opts) {
	const { stringtopic, log } = opts
	log({ type: 'no open tasks', data: { text: 'end streams, leave swarm, close feeds, destroy discovery', stringtopic } })
	const { swarm, sockets, topics, tasks } = account.cache 
	delete tasks[stringtopic]
	const remotekeys = Object.keys(topics[stringtopic].sockets)
	// close all the streams
	remotekeys.forEach(key => {
		const { socket, replicationStream } = sockets[key]
		// if socket not in use, close it
		socket.end()
		replicationStream.end()
		// delete the socket object
		delete sockets[key]
		delete account.cache.sockets[key]
	})
	// swarm leave topic
	swarm.leave(b4a.from(stringtopic, 'hex'))
	// close all the feeds
	const feedkeys = Object.keys(topics[stringtopic].feeds)
	feedkeys.forEach(async key => {
		const {feed} = topics[stringtopic].feeds[key]
		await feed.core.close()
	})
	// destroy the discovery
	// topics[stringtopic].discovery.leave()
	const discovery = await topics[stringtopic].discovery
	if (discovery) await discovery.destroy()
	// delete the topic object
	delete topics[stringtopic]
}


////////////////////////////////////////

function onconnection (account, log) {
	return (connection, peerInfo) => {
		log({ type: 'onconnection', data: { text: 'connection callback' } })

		const sockets = account.cache.sockets
		const topics = account.cache.topics
		const Peers = account.cache.peers
		const remotekey = peerInfo.publicKey
		const remotestringkey = remotekey.toString('hex')

		if (sockets[remotestringkey]) {
			log({ type: 'onconnection', data: { text: 'existing connection', remotestringkey, isInitiator: connection.isInitiator } })
			replicationStream = sockets[remotestringkey].replicationStream
		} else {
			log({ type: 'onconnection', data: { text: 'new connection', remotestringkey, isInitiator: connection.isInitiator } })
			replicationStream = hypercore.createProtocolStream(connection, { ondiscoverykey })
			sockets[remotestringkey] = { socket: connection, replicationStream }
		}
		
		if (peerInfo.topics.length) {
			if (Peers[remotestringkey]) return exchange_key(remotestringkey)
			for (var i = 0, len = peerInfo.topics.length; i < len; i++) {
				const Topic = peerInfo.topics[i].toString('hex')
				log({ type: 'onconnection', data: { text: 'looping over topics', count: peerInfo.topics.length, i, Topic } })
				if (topics[Topic]) {
					log({ type: 'onconnection', data: { text: 'matching topic - client', remotestringkey, isInitiator: connection.isInitiator, topic: Topic } })
					set_socket({ topics, topic: Topic, key: remotestringkey, sockets})
					replicate_feeds({ topics, topic: Topic })
				}
			}
		} 
		
		function ondiscoverykey (discoverykey) { // client hasn't replicated the hypercores so they are asking for the 'discovery-key' event
			if (Peers[remotestringkey]) return exchange_key(remotestringkey)
			log({ type: 'onconnection', data: { text: 'on discovery key' } })
			const Topic = discoverykey.toString('hex')
			if (topics[Topic]) {
				log({ type: 'onconnection', data: { text: 'matching topic - server', remotestringkey, isInitiator: connection.isInitiator, topic: Topic } })
				set_socket({ topics, topic: Topic, key: remotestringkey, sockets})
				if (Peers[Topic] && Peers[Topic].peerList.includes(remotestringkey)) return exchange_key({ remotestringkey, stringtopic: Topic })
				replicate_feeds({ topics, topic: Topic })
			}
		}

		function set_socket ({ topics, topic, key, sockets}) {
			if (!topics[topic].sockets[[key]]) {
				topics[topic].sockets[key] = sockets[key]
			}
		}

		function replicate_feeds ({ topics, topic}) {
			log({ type: 'onconnection', data: { text: 'feeds for topic', topic, count: Object.keys(topics[topic].feeds).length } })
			Object.keys(topics[topic].feeds).forEach(key => {
				const feed = topics[topic].feeds[key].feed
				log({ type: 'onconnection', data: { text: 'replicating feed', feedkey: feed.key.toString('hex') } })
				feed.replicate(replicationStream)
			}) 
		}


		function exchange_key (remotestringkey) {
			const peers_topics = Object.keys(Peers[remotestringkey]) 
			// peers_topics.forEach(topic => {
			// 	const { feed, onpeer, msg: { send, receive } } = Peers[remotestringkey][topic]
			// 	log({ type: 'onconnection', data: { text: `is on peerList`, remotestringkey, peers_topics  } })
			// 	try {
			// 		if (send) {
			// 			log({ type: 'onconnection', data: { text: `sending the message` } })
			// 			replicationStream.write((JSON.stringify({ type: 'feedkey', feedkey: feed.key.toString('hex') })))
			// 			log({ type: 'onconnection', data: { text: 'msg sent - feedkey', feedkey: feed.key.toString('hex') }})
			// 			replicate_to_peer(onpeer, topic)
			// 			// replicationStream.on('data', async (message) => {
			// 			// 	const { type, ack } = JSON.parse(message.toString('utf-8'))
			// 			// 	log({ type: 'onconnection', data: { text: 'feedkey-ack received' }})
			// 			// 	if (type === 'feedkey-ack') replicate_to_peer(onpeer, topic)
			// 			// })
			// 		} else if (receive) {
			// 			log({ type: 'onconnection', data: { text: `receiving the message` } })
			// 			replicationStream.on('data', async (message) => {
			// 				const { type, feedkey } = JSON.parse(message.toString('utf-8'))
			// 				console.log({ name: log.path, text: 'receiver', message })
			// 				if (type === 'feedkey') {	
			// 					// replicationStream.write((JSON.stringify({ type: 'feedkey-ack' })))
			// 					// 1. Make feed
			// 					log({ type: 'onconnection', data: { text: 'msg received - feedkey', feedkey: feedkey.toString('hex') }})
			// 					feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
			// 					await feed.ready()
			// 					feedkey = feed.key
			// 					stringkey = feedkey.toString('hex')
			// 					topics[stringtopic].feeds[stringkey] = { feed }
			// 					log({ type: 'onconnection', data: { text: 'New feed - exchange key', stringkey }})
			// 					replicate_to_peer(onpeer, topic)
			// 				}
			// 			})	
			// 		}
			// 	} catch (err) {
			// 		log({ type: 'error', data: { text: 'Error: is on peerList', err } })
			// 	}
			// })
			peers_topics.forEach(topic => {
				const { feed, onpeer, msg: { send, receive } } = Peers[remotestringkey][topic]
				log({ type: 'onconnection', data: { text: `is on peerList`, remotestringkey, peers_topics  } })
				try {
					if (send) {
						log({ type: 'onconnection', data: { text: `sending the message` } })
						replicationStream.write((JSON.stringify({ type: 'feedkey', feedkey: feed.key.toString('hex') })))
						log({ type: 'onconnection', data: { text: 'msg sent - feedkey', feedkey: feed.key.toString('hex') }})
						replicate_to_peer(onpeer, topic)
						// replicationStream.on('data', async (message) => {
						// 	const { type, ack } = JSON.parse(message.toString('utf-8'))
						// 	log({ type: 'onconnection', data: { text: 'feedkey-ack received' }})
						// 	if (type === 'feedkey-ack') replicate_to_peer(onpeer, topic)
						// })
					}
				} catch (err) {
					log({ type: 'error', data: { text: 'Error: is on peerList', err } })
				}
			})

			peers_topics.forEach(topic => {
				const { feed, onpeer, msg: { send, receive } } = Peers[remotestringkey][topic]
				log({ type: 'onconnection', data: { text: `is on peerList`, remotestringkey, peers_topics  } })
				try {
					if (receive) {
						log({ type: 'onconnection', data: { text: `receiving the message` } })
						replicationStream.on('data', async (message) => {
							const { type, feedkey } = JSON.parse(message.toString('utf-8'))
							console.log({ name: log.path, text: 'receiver', message })
							if (type === 'feedkey') {	
								// replicationStream.write((JSON.stringify({ type: 'feedkey-ack' })))
								// 1. Make feed
								log({ type: 'onconnection', data: { text: 'msg received - feedkey', feedkey: feedkey.toString('hex') }})
								feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
								await feed.ready()
								feedkey = feed.key
								stringkey = feedkey.toString('hex')
								topics[stringtopic].feeds[stringkey] = { feed }
								log({ type: 'onconnection', data: { text: 'New feed - exchange key', stringkey }})
								replicate_to_peer(onpeer, topic)
							}
						})	
					}
				} catch (err) {
					log({ type: 'error', data: { text: 'Error: is on peerList', err } })
				}
			})

			function replicate_to_peer (onpeer, topic) {
				feed.replicate(replicationStream)
				Peers[remotestringkey][topic] = void 0
				if (peers_topics.length === 0) delete Peers[remotestringkey]
				return onpeer({ feed, remotekey: remotestringkey })
			}
		}



		replicationStream.on('close', (err) => { log({ type: 'onconnection', data: { text: `Error: replicationStream closed` } }) })
		replicationStream.on('end', (err) => { log({ type: 'onconnection', data: { text: `Error: replicationStream ended` } }) })
		replicationStream.on('timeout', (err) => { log({ type: 'onconnection', data: { text: `Error: replicationStream timed out` } }) })
	}
}

////////////////////////////////////////

/* 
account = {
    cache:  {
        swarm,
        sockets: {
            remotekey: { 
                socket, 
                replicationStream
            }
        },
        topics: {
            stringtopic: {
                discovery,
                feeds: {
                    stringkey: { feed }
                },
                sockets: {
                    remotekey: account.cache.sockets[remotekey]
                },
            }
        },
				// peers are created only when we have a msg (send or receive) and a peerList and we need to exchange keys first and then replicate
				peers: {  
					remotestringkey: {
						stringtopic1: { feed, msg: { receive, send }, onpeer },
						stringtopic2: { feed, msg: { receive, send }, onpeer }
					}
				},
        tasks: {
            stringkey: counter
        }
    },
    storage: {
        feedkey: { feed, db, discovery, unintercept }
    }
} 

*/

