const hyperswarm = require('hyperswarm')
const hypercore = require('hypercore')
const RAM = require('random-access-memory')
const datdot_crypto = require('../datdot-crypto')
const b4a = require('b4a')
const Protomux = require('protomux')
const SecretStream = require('@hyperswarm/secret-stream')
const c = require('compact-encoding')


module.exports = feed_store

function feed_store (account, bootstrap) {
	const api = {
		load_feed: (opts) => _load_feed(account, opts),
		connect: (opts) => _connect(account, bootstrap, opts),
		no_tasks: (opts) => _no_tasks(account, opts)
	}
	return api
}

function noop () {}

/* --------------------------------------------------------------------------------------------

																				LOAD FEED

-----------------------------------------------------------------------------------------------*/
async function _load_feed(account, { newfeed = true, feedkey, topic, log }) { // newfeed false for 
	log({ type: 'feed-store', data: { text: 'loading feed', feedkey, topic }})
	
	var feed
	var stringkey
	var stringtopic
	if (!account.cache) account.cache = { sockets: {}, topics: {}, feeds: {}, peers: {}, tasks: {} }
	const feeds = account.cache.feeds
	
	// 0. If feedkey and/or topic, get stringkey and stringtopic
	if (topic) { // when msg.receive or msg.send (no feedkey, only topic)
		topic = Buffer.isBuffer(topic) ? topic : b4a.from(topic, 'hex')
		stringtopic = topic.toString('hex') 
	}
	if (feedkey) { // when feed key with or without topic
		feedkey = Buffer.isBuffer(feedkey) ? feedkey : b4a.from(feedkey, 'hex')
		stringkey = feedkey.toString('hex')
		if (!topic) {
			topic = datdot_crypto.get_discoverykey(feedkey)
			stringtopic = topic.toString('hex')
		}
	} 
	
	// 1. Get or make feed
	if (stringtopic && feeds[stringtopic]) { // get existing feed
		feed = feeds[stringtopic][stringkey].feed 
		log({ type: 'feed-store', data: { text: 'Existing feed', stringkey, stringtopic }})
	} else { // make new feed
		if (newfeed) { 
			if (feedkey) {
				log({ type: 'feed-store', data: { text: 'Making new feed with feedkey', stringkey, stringtopic }})
				feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
				await feed.ready()
			} else {
				feed = new hypercore(RAM, { valueEncoding: 'binary', sparse: true })
				log({ type: 'feed-store', data: { text: 'Making new feed without feedkey', stringkey, stringtopic }})
				await feed.ready()
				feedkey = feed.key
				stringkey = feedkey.toString('hex')
				if (!topic) topic = datdot_crypto.get_discoverykey(feedkey)
				if (!stringtopic) stringtopic = topic.toString('hex')
			}
			log({ type: 'feed-store', data: { text: 'New feed', stringkey, stringtopic }})
		}
		// 2. Store topic and new feed (if available)
		feeds[stringtopic] = {}  // add topic to the feeds
		if (feed) feeds[stringtopic] = { [stringkey]: { feed } }
		log({ type: 'feed-store', data: { text: 'New topic stored in cache', stringtopic }})
	}

	log({ type: 'feed-store', data: { text: 'returning feed', stringkey }})
	return { feed }
	
}

/* --------------------------------------------------------------------------------------------

																				CONNECT

-----------------------------------------------------------------------------------------------*/
async function _connect ( account, bootstrap, { swarm_opts, peers, log }) {
	log({ type: 'connect', data: { text: 'connecting to peer(s)' }})
	const { noisePublicKey, noisePrivateKey } = account
	console.log({bootstrap, noisePublicKey, peers, swarm_opts })
	
	peers = Object.assign({ peerList: [], onpeer: noop, msg: {} }, peers)
	const { peerList, onpeer, msg, feed } = peers
	var { topic, mode } = swarm_opts
	var stringtopic
	var swarm
	var discovery
	
	if (topic)
	topic = Buffer.isBuffer(topic) ? topic : b4a.from(topic, 'hex')
	stringtopic = topic.toString('hex') 
	if (!topic) throw new Error('Can not connect without topic')
	

	// 1. Add task
	const tasks = account.cache.tasks
	const topics = account.cache.topics
	if (!tasks[stringtopic]) tasks[stringtopic] = 1
	else tasks[stringtopic]++

	// 2. Make swarm
	if (!account.cache.swarm) {
		swarm = new hyperswarm({ 
			bootstrap, 
			keyPair: { publicKey: noisePublicKey, secretKey: noisePrivateKey }, 
			maxParallel: Infinity,
			maxPeers: Infinity 
		})
		account.cache.swarm = swarm
		log({ type: 'store connect', data: { text: 'new swarm', mode }})
		swarm.on('connection', onconnection(account, log))
	} else swarm = account.cache.swarm

	// 3. Store topic and feed (for new feed)
	if (!topics[stringtopic]) topics[stringtopic] = { sockets: {} } // add topic to the cache
	log({ type: 'feed-store', data: { text: 'New topic stored in cache', stringtopic }})

	// 3. Join peer through existing channel or join the swarm on topic
	var discovery = swarm.status(topic)

	if (peerList.length === 0) { // Join topic (if no peerList && no discovery yet)
		if (!discovery) {
			log({ type: 'store connect', data: { text: 'making new discovery' }})
			await swarm.join(topic, mode).flushed()
			topics[stringtopic].discovery = swarm.status(topic)
			log({ type: 'store connect', data: { text: 'joined the swarm', mode, stringtopic }})
		}
	} else { // connect only to the peers on the list
		log({ type: 'store connect', data: { text: 'connecting only to peers', peerList: peerList.length }})
		for (var i = 0; i < peerList.length; i++) {
			const remotestringkey = peerList[i]
			const peers = account.cache.peers
			if (!peers[remotestringkey]) peers[remotestringkey] = { topics: { [stringtopic]: { onpeer, feed, msg, log } } }
			else peers[remotestringkey].topics[stringtopic] = { onpeer, feed, msg, log }
			
			const sockets = account.cache.sockets
			console.log({ logging_name: log.path, sockets, peer_topics: Object.keys(account.cache.peers[remotestringkey].topics), remotestringkey, stringtopic, topics })
			
			if (sockets[remotestringkey]) {
				log({ type: 'store connect', data: { text: 'existing socket' }})
				exchange_feedkey({ account, remotestringkey, log }) // feed will be returned with onpeer callback
				continue
			} else {				
				// Join peer (if no socket connection && no discovery yet)
				swarm.joinPeer(b4a.from(remotestringkey, 'hex'))
			}
	
		}
	}
	
}





/* --------------------------------------------------------------------------------------------

																				ONCONNECTION

-----------------------------------------------------------------------------------------------*/

function onconnection (account, log) {
	return (connection, peerInfo) => {
		log({ type: 'onconnection', data: { text: 'connection callback' } })
		
		const topics = account.cache.topics
		const sockets = account.cache.sockets
		const remotekey = peerInfo.publicKey
		const remotestringkey = remotekey.toString('hex')	
		const target = account.cache.peers[remotestringkey]
		
		const { replicationStream } = load_replicationStream_and_channel({ account, connection, remotestringkey, log })
		if (target) return exchange_feedkey({ account, remotestringkey, log }) // this is the peer we need to exchange feedkeys with

		// handle client (isInitiator is true)
		if (peerInfo.topics.length) {
			for (var i = 0, len = peerInfo.topics.length; i < len; i++) {
				const stringtopic = peerInfo.topics[i].toString('hex') // only shows topics derived from a feed.discoveryKey
				log({ type: 'onconnection - client', data: { text: 'looping over topics', count: peerInfo.topics.length, i, stringtopic } })
				if (topics[stringtopic]) {
					log({ type: 'onconnection - client', data: { text: 'matching topic', remotestringkey, isInitiator: connection.isInitiator, stringtopic } })
					set_socket({ topics, stringtopic, key: remotestringkey, sockets, log })
					replicate_feeds({ account, remotestringkey, stringtopic, replicationStream, log })
				}
			}
		} 
		
	}
}		
/*-----------------------------------------------------------------------------------------------------
		
																										HELPERS
		
		------------------------------------------------------------------------------------------------------*/
	function set_socket ({ topics, stringtopic, key, sockets, log}) {
		if (!topics[stringtopic].sockets[[key]]) {
			topics[stringtopic].sockets[key] = sockets[key]
		}
	}
	
	function load_replicationStream_and_channel ({ account, connection, remotestringkey, log }) {
		const sockets = account.cache.sockets
		const topics = account.cache.topics
		const target = account.cache.peers[remotestringkey]
		var replicationStream
		var mux

		if (sockets[remotestringkey]) {
			log({ type: 'onconnection', data: { text: 'existing connection', remotestringkey, isInitiator: connection.isInitiator } })
			replicationStream = sockets[remotestringkey].replicationStream
			mux = sockets[remotestringkey].mux
		} else {
			log({ type: 'onconnection', data: { text: 'new connection', remotestringkey, isInitiator: connection.isInitiator } })
			replicationStream = hypercore.createProtocolStream(connection, { ondiscoverykey })
			mux = hypercore.getProtocolMuxer(replicationStream)
			sockets[remotestringkey] = { socket: connection, replicationStream, mux }
			// new_channel({ account, remotestringkey, log })
		}
		
		replicationStream.on('close', (err) => { log({ type: 'onconnection', data: { text: `Error: replicationStream closed` } }) })
		replicationStream.on('end', (err) => { log({ type: 'onconnection', data: { text: `Error: replicationStream ended` } }) })
		replicationStream.on('timeout', (err) => { log({ type: 'onconnection', data: { text: `Error: replicationStream timed out` } }) })

		return { replicationStream }

		// handle server (isInitiator is false)
		function ondiscoverykey (discoverykey) { // client hasn't replicated the hypercores so they are asking for the 'discovery-key' event
			log({ type: 'ondiscovery', data: { text: 'on discovery key' } })
			if (target) return // if peer from the peerList, don't do anything
			const stringtopic = discoverykey.toString('hex') // only shows topics derived from a feed.discoveryKey
			if (topics[stringtopic]) {
				// const { replicationStream } = load_replicationStream_and_channel({ account, connection, remotestringkey, log })
				log({ type: 'ondiscovery', data: { text: 'matching topic', remotestringkey, isInitiator: connection.isInitiator, stringtopic } })
				set_socket({ topics, stringtopic, key: remotestringkey, sockets, log })
				replicate_feeds({ account, remotestringkey, stringtopic, replicationStream, log })
			}
		}
	}
	
	function new_channel ({ account, remotestringkey, log }) {
		const sockets = account.cache.sockets
		const { mux } = sockets[remotestringkey]
		const channel = mux.createChannel({
			protocol: 'exchange-feedkey',
			onopen () { log({ type: 'open protomux channel', data: { text: 'onopen: the other side opened this protocol!' }}) },
			onclose () { log({ type: 'open protomux channel', data: { text: 'onclose: either side closed the protocol' }}) },
		})
		channel.open() // open
		
		sockets[remotestringkey].channel = channel
		log({ type: 'open protomux channel', data: { text: `new channel` } })
		
		// add message types for different encodings (i.e. string...)
		sockets[remotestringkey].mux_msg_types = { string_msg: channel.addMessage({ encoding: c.string }) }
		const string_msg = sockets[remotestringkey].mux_msg_types.string_msg
		
		// load registry to store onmessage call backs and undelivered messages (msg_queue) for each stringtopic
		var registry = string_msg.registry
		if (!registry) registry = string_msg.registry = new Map()
		log({ type: 'open protomux channel', data: { text: `registry loaded` } })
		
		// intercept onmessage with dispacher that will call the right callback
		string_msg.onmessage = dispacher
		log({ type: 'open protomux channel', data: { text: `onmessage set to dispacher` } })
		
		function dispacher (buffer) {
			const message = JSON.parse(buffer.toString('utf-8'))
			const { stringtopic } = message
			const entry = registry.get(stringtopic)
			console.log(log.path, 'entry_registry_stringtopic_dispacher', entry)
			if (entry) {
				const { onmessage, msg_queue } = entry
				onmessage ? onmessage(buffer) : msg_queue.push(buffer)
			} else {
				registry.set(stringtopic, { msg_queue: [buffer] })
			}
			
			log({ type: 'open protomux channel', data: { text: `dispacher gets onmessage`, message, registry: [...registry.entries()] } })
		}
	}

		function replicate_feeds ({ account, stringtopic, replicationStream, log }) {
			const swarm = account.cache.swarm
			const topic = b4a.from(stringtopic, 'hex')
			const status = swarm.status(topic)
			if (!status) return

			const feeds = account.cache.feeds
			log({ type: 'replicate feeds', data: { text: 'feeds for topic', stringtopic, count: Object.keys(feeds[stringtopic]).length } })
			Object.keys(feeds[stringtopic]).forEach(key => {
				const feed = feeds[stringtopic][key].feed
				log({ type: 'replicate feeds', data: { text: 'replicating feed', feedkey: feed.key.toString('hex') } })
				feed.replicate(replicationStream)
			}) 
			if (!status.isServer) {
				swarm.leave(topic) // stop getting new connections on topic. leave will not close any existing connections.
			}
		}
		
		function exchange_feedkey ({ account, remotestringkey, log }) { //get feedkey from or send to a target peer (on each custom topic)
			log({ type: 'exchange feedkey', data: { text: `is on peerList`, remotestringkey  } })				
			const Peers = account.cache.peers
			const sockets = account.cache.sockets
			const topics = account.cache.topics
			const feeds = account.cache.feeds
			const peer_topics = Object.keys(Peers[remotestringkey].topics)
			const { replicationStream } = sockets[remotestringkey]

			if (!sockets[remotestringkey].channel) new_channel({ account, remotestringkey, log })

			// get string message type for sending strings through the mux channel with that peer (channel.addMessage(...))
			const string_msg = sockets[remotestringkey].mux_msg_types.string_msg
			// load registry
			var registry = string_msg.registry
			if (!registry) registry = string_msg.registry = new Map()

			log({ type: 'exchange feedkey', data: { text: `is on for peer and topic`, remotestringkey, peer_topics  } })				
			
			// we need to loop over all the topics for this peer we just got connected to 
			// in order to find all the topics we have to connect for (peerInfo.topics only shows
			// topics derived from a feedkey, not custom topics
			peer_topics.forEach(stringtopic => {
				const { msg: { send, receive }, log } = Peers[remotestringkey].topics[stringtopic]
				log({ type: 'exchange feedkey', data: { text: `current peer ${remotestringkey} for topic ${stringtopic}`, peer_topics  } })
				
				// get entry for stringtopic
				const entry = registry.get(stringtopic)
				console.log(log.path, 'entry_registry_stringtopic_exchange', entry)
				
				if (entry) {
					console.log({entry})
					const { onmessage, msg_queue } = entry
					if (msg_queue) entry.msg_queue.forEach(onmessage)
					entry.msg_queue = void 0
					entry.onmessage = onmessage
				} else {
					string_msg.registry.set(stringtopic, { onmessage })
					console.log({string_msg})
				}
				
				try {
					if (send) { // see if for this topic we send or receive a message
						const { feed } = Peers[remotestringkey].topics[stringtopic]
						log({ type: 'exchange feedkey', data: { text: `sending the message` } })
						console.log({ who: 'send', name: log.path, string_msg })
						string_msg.send(JSON.stringify({ type: 'feedkey', feedkey: feed.key.toString('hex'), stringtopic }))
						log({ type: 'exchange feedkey', data: { text: 'msg sent - feedkey', feedkey: feed.key.toString('hex'), stringtopic }})
					} else if (receive) {
						log({ type: 'exchange feedkey', data: { text: `receiving the message` } })
					}
				} catch (err) {
					log({ type: 'error', data: { text: 'Error: is on peerList', err } })
				}
				
			})

			async function onmessage (message) {
				const { type, feedkey, stringtopic } = JSON.parse(message.toString('utf-8'))
				const { onpeer, msg, log } = Peers[remotestringkey].topics[stringtopic]
				var feed
				console.log({ name: log.path, text: 'onmessage mux', type, feedkey, stringtopic })
				if (type === 'feedkey') {	
					// replicationStream.write((JSON.stringify({ type: 'feedkey-ack' })))
					// 1. Make feed
					log({ type: 'onmessage protomux', data: { text: 'msg received - feedkey', feedkey: feedkey.toString('hex') }})
					feed = new hypercore(RAM, feedkey, { valueEncoding: 'binary', sparse: true })
					await feed.ready()
					// feedkey = feed.key
					stringkey = feedkey.toString('hex')
					feeds[stringtopic][stringkey] = { feed }
					log({ type: 'onmessage protomux', data: { text: 'New feed - exchange key', stringkey }})
					string_msg.send(JSON.stringify({ type: 'ack-feedkey', feedkey: feed.key.toString('hex'), stringtopic }))
					replicate_to_peer({ account, onpeer, feed, replicationStream, stringtopic, log })
					string_msg.registry.delete(stringtopic)
				} 
				else if (type === 'ack-feedkey') {
					feed = Peers[remotestringkey].topics[stringtopic].feed
					const stringkey = feed.key.toString('hex')
					log({ type: 'onmessage protomux', data: { text: 'Ack received', stringkey }})
					replicate_to_peer({ account, onpeer, feed, replicationStream, stringtopic, log })
					string_msg.registry.delete(stringtopic)
					// sockets[remotestringkey].channel.close()
				}

			function replicate_to_peer ({ onpeer, feed, replicationStream, stringtopic, log }) {
				const Peers = account.cache.peers
				log({ type: 'replicate feed', data: { text: 'Replicate to peer' }})
				feed.replicate(replicationStream)
				Peers[remotestringkey].topics[stringtopic] = void 0
				if (peer_topics.length === 0) delete Peers[remotestringkey]
				onpeer({ feed, remotekey: remotestringkey })
			}
		}
		
			
	}

async function _no_tasks (account, opts) {
	const { stringtopic, log } = opts
	log({ type: 'no open tasks', data: { text: 'end streams, leave swarm, close feeds, destroy discovery', stringtopic } })
	const { swarm, sockets, feeds, topics, tasks } = account.cache 
	delete tasks[stringtopic]
	const remotekeys = Object.keys(topics[stringtopic].sockets)
	// close all the streams
	remotekeys.forEach(key => {
		const { socket, replicationStream, channel } = sockets[key]
		// if socket not in use, close it
		socket.end()
		replicationStream.end()
		if (channel) channel.close()
		// delete the socket object
		delete sockets[key]
		delete account.cache.sockets[key]
	})
	// swarm leave topic
	swarm.leave(b4a.from(stringtopic, 'hex'))
	// close all the feeds
	const stringkeys = Object.keys(feeds[stringtopic])
	if (stringkeys) {
		stringkeys.forEach(async key => {
			const {feed} = feeds[stringtopic][key]
			await feed.core.close()
		})
	}
	// destroy the discovery
	// topics[stringtopic].discovery.leave()
	const discovery = await topics[stringtopic].discovery
	if (discovery) await discovery.destroy()
	// delete the topic object
	delete topics[stringtopic]
}

/* --------------------------------------------------------------------------------------------

																				CACHE

-----------------------------------------------------------------------------------------------*/

/* 
account = {
    cache:  {
        swarm,
        sockets: {
            remotekey: { 
                socket, 
                replicationStream,
								mux,
								channel,
								mux_msg_types: { string_msg: { registry, onmessage: dispacher } }
            }
        },
        topics: {
            stringtopic: {
                discovery,
            }
        },
				feeds: {
					stringtopic: {
						stringkey: { feed }
					}
				}
				// peers are created only when we have a msg (send or receive) and a peerList and we need to exchange keys first and then replicate
				peers: {  
					remotestringkey: {
						stringtopic1: { feed, msg: { receive, send }, onpeer },
						stringtopic2: { feed, msg: { receive, send }, onpeer }
					}
				},
        tasks: {
            stringkey: counter
        }
    },
    storage: {
        feedkey: { feed, db, discovery, unintercept }
    }
} 

*/

